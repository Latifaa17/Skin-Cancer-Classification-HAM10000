{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install efficientnet_pytorch torchtoolbox","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-05-14T14:43:23.804544Z","iopub.execute_input":"2023-05-14T14:43:23.804909Z","iopub.status.idle":"2023-05-14T14:43:34.933592Z","shell.execute_reply.started":"2023-05-14T14:43:23.804876Z","shell.execute_reply":"2023-05-14T14:43:34.932541Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting efficientnet_pytorch\n  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\nCollecting torchtoolbox\n  Downloading torchtoolbox-0.1.8.2-py3-none-any.whl (84 kB)\n\u001b[K     |████████████████████████████████| 84 kB 3.9 MB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet_pytorch) (1.5.0)\nRequirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (4.2.0.34)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (1.4.1)\nRequirement already satisfied: prettytable in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (0.7.2)\nCollecting lmdb\n  Downloading lmdb-1.4.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (294 kB)\n\u001b[K     |████████████████████████████████| 294 kB 49.3 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (1.18.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (1.14.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (4.45.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (5.3.1)\nRequirement already satisfied: tensorboard in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (2.1.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (0.22.2.post1)\nRequirement already satisfied: pyarrow in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (0.16.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (2.9.0)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet_pytorch) (0.18.2)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (0.4.1)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (1.14.0)\nRequirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (3.11.4)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (46.1.3.post20200325)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (0.9.0)\nRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (0.34.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (2.23.0)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (1.0.1)\nRequirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (1.28.1)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (3.2.1)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->torchtoolbox) (0.14.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers->torchtoolbox) (2020.4.4)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers->torchtoolbox) (0.0.43)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from transformers->torchtoolbox) (0.1.86)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers->torchtoolbox) (3.0.10)\nRequirement already satisfied: tokenizers==0.7.0 in /opt/conda/lib/python3.7/site-packages (from transformers->torchtoolbox) (0.7.0)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->torchtoolbox) (1.2.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->torchtoolbox) (0.2.7)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->torchtoolbox) (3.1.1)\nRequirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->torchtoolbox) (4.0)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->torchtoolbox) (3.0.4)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->torchtoolbox) (2.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->torchtoolbox) (2020.4.5.1)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->torchtoolbox) (1.24.3)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers->torchtoolbox) (7.1.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->torchtoolbox) (3.0.1)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->torchtoolbox) (0.4.8)\nBuilding wheels for collected packages: efficientnet-pytorch\n  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=c06379a026e2ded41935e548bec17960224c71486b3f259bcefac4eef548b8f4\n  Stored in directory: /root/.cache/pip/wheels/0e/cc/b2/49e74588263573ff778da58cc99b9c6349b496636a7e165be6\nSuccessfully built efficientnet-pytorch\nInstalling collected packages: efficientnet-pytorch, lmdb, torchtoolbox\nSuccessfully installed efficientnet-pytorch-0.7.1 lmdb-1.4.1 torchtoolbox-0.1.8.2\n\u001b[33mWARNING: You are using pip version 20.1; however, version 23.1.2 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torchvision\nfrom torchvision import models,transforms\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom torchvision import transforms\nfrom torch.utils.data.sampler import RandomSampler, SequentialSampler\n\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold\nimport pandas as pd\nimport numpy as np\nimport gc\nimport os\nimport cv2\nimport time\nimport datetime\nimport warnings\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom efficientnet_pytorch import EfficientNet\n\nfrom sklearn.model_selection import train_test_split\n\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-14T14:43:34.935784Z","iopub.execute_input":"2023-05-14T14:43:34.936552Z","iopub.status.idle":"2023-05-14T14:43:36.642280Z","shell.execute_reply.started":"2023-05-14T14:43:34.936510Z","shell.execute_reply":"2023-05-14T14:43:36.641494Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-05-14T14:43:36.643824Z","iopub.execute_input":"2023-05-14T14:43:36.644201Z","iopub.status.idle":"2023-05-14T14:43:36.649210Z","shell.execute_reply.started":"2023-05-14T14:43:36.644161Z","shell.execute_reply":"2023-05-14T14:43:36.648172Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# At least fixing some random seeds. \n# It is still impossible to make results 100% reproducible when using GPU\nwarnings.simplefilter('ignore')\ntorch.manual_seed(47)\nnp.random.seed(47)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T14:43:36.650669Z","iopub.execute_input":"2023-05-14T14:43:36.651223Z","iopub.status.idle":"2023-05-14T14:43:36.660216Z","shell.execute_reply.started":"2023-05-14T14:43:36.651180Z","shell.execute_reply":"2023-05-14T14:43:36.659493Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-05-14T14:43:36.665392Z","iopub.execute_input":"2023-05-14T14:43:36.665666Z","iopub.status.idle":"2023-05-14T14:43:36.691168Z","shell.execute_reply.started":"2023-05-14T14:43:36.665639Z","shell.execute_reply":"2023-05-14T14:43:36.690130Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class MelanomaDataset(Dataset):\n    def __init__(self, df: pd.DataFrame, train: bool = True, transforms = None, meta_features = None):\n        \"\"\"\n        Class initialization\n        Args:\n            df (pd.DataFrame): DataFrame with data description\n            imfolder (str): folder with images\n            train (bool): flag of whether a training dataset is being initialized or testing one\n            transforms: image transformation method to be applied\n            meta_features (list): list of features with meta information, such as sex and age\n            \n        \"\"\"\n        self.df = df\n        self.path1 = '/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1'\n        self.path2 = '/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2'\n        self.transforms = transforms\n        self.train = train\n        self.meta_features = meta_features\n        \n    def __getitem__(self, index):\n        image_path = os.path.join(self.path1, self.df.iloc[index]['image_id'] + '.jpg')\n        if os.path.exists(image_path):\n            image = cv2.imread(image_path)\n        else:\n            # If the image is not in part 1, try to load it from part 2\n            image_path = os.path.join(self.path2, self.df.iloc[index]['image_id'] + '.jpg')\n            if os.path.exists(image_path):\n                image = cv2.imread(image_path)\n                \n        meta = np.array(self.df.iloc[index][self.meta_features].values, dtype=np.float32)\n\n        if self.transforms:\n            x = self.transforms(image)\n            \n        if self.train:\n            y = self.df.iloc[index]['target']\n            return (x, meta), y\n        else:\n            return (x, meta)\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def _get_label(self, dataset, idx):\n        return self.df.iloc[idx]['target']\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-14T14:43:36.695100Z","iopub.execute_input":"2023-05-14T14:43:36.695422Z","iopub.status.idle":"2023-05-14T14:43:36.712707Z","shell.execute_reply.started":"2023-05-14T14:43:36.695380Z","shell.execute_reply":"2023-05-14T14:43:36.711902Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n])\ntest_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n])\n","metadata":{"execution":{"iopub.status.busy":"2023-05-14T14:43:36.715442Z","iopub.execute_input":"2023-05-14T14:43:36.716063Z","iopub.status.idle":"2023-05-14T14:43:36.723655Z","shell.execute_reply.started":"2023-05-14T14:43:36.716020Z","shell.execute_reply":"2023-05-14T14:43:36.722917Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# df = pd.read_csv('/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv')\n# df = pd.read_csv('/kaggle/input/meta-abcd/metadata_ABCD.csv')\ndf = pd.read_csv('/kaggle/input/metadata-fromcnn/metadata_fromCNN.csv')\n\n\n# this will tell us how many images are associated with each lesion_id\ndf_undup = df.groupby('lesion_id').count()\n# now we filter out lesion_id's that have only one image associated with it\ndf_undup = df_undup[df_undup['image_id'] == 1]\ndf_undup.reset_index(inplace=True)\n\ndef get_duplicates(x):\n    unique_list = list(df_undup['lesion_id'])\n    if x in unique_list:\n        return 'unduplicated'\n    else:\n        return 'duplicated'\n\n# create a new colum that is a copy of the lesion_id column\ndf['duplicates'] = df['lesion_id']\n# apply the function to this new column\ndf['duplicates'] = df['duplicates'].apply(get_duplicates)\n\ndf_undup  = df[df['duplicates'] == 'unduplicated']\n\n#now we create a test set using df_undup because we are sure that none of these images have augmented duplicates in the train set\ny = df_undup['dx']\n_, test_df_csv = train_test_split(df_undup, test_size=0.7265, random_state=101, stratify=y)\ntest_df_csv.shape\n\n# This set will be df_original excluding all rows that are in the test set\n# This function identifies if an image is part of the train or test set.\ndef get_test_rows(x):\n    # create a list of all the lesion_id's in the val test\n    test_list = list(test_df_csv['image_id'])\n    if str(x) in test_list:\n        return 'test'\n    else:\n        return 'train'\n\n# identify train and test rows\n# create a new colum that is a copy of the image_id column\ndf['train_or_test'] = df['image_id']\n# apply the function to this new column\ndf['train_or_test'] = df['train_or_test'].apply(get_test_rows)\n# filter out train rows\ntrain_df_csv = df[df['train_or_test'] == 'train']\n\n# Split the test into 50% test and 50% validation\ntest_df, val_df = train_test_split(test_df_csv, test_size=0.5, random_state=101, stratify=test_df_csv['dx'])\n\ntrain_df = train_df_csv\nprint(len(train_df))\nprint(len(val_df))\nprint(len(test_df))","metadata":{"execution":{"iopub.status.busy":"2023-05-14T14:43:36.724913Z","iopub.execute_input":"2023-05-14T14:43:36.725474Z","iopub.status.idle":"2023-05-14T14:43:50.349914Z","shell.execute_reply.started":"2023-05-14T14:43:36.725424Z","shell.execute_reply":"2023-05-14T14:43:50.348476Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"6009\n2003\n2003\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df.dx.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-05-14T14:43:50.351400Z","iopub.execute_input":"2023-05-14T14:43:50.351767Z","iopub.status.idle":"2023-05-14T14:43:50.365390Z","shell.execute_reply.started":"2023-05-14T14:43:50.351727Z","shell.execute_reply":"2023-05-14T14:43:50.364395Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"nv       3497\nmel       946\nbkl       779\nbcc       387\nakiec     217\nvasc       96\ndf         87\nName: dx, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ntrain_df['target'] = le.fit_transform(train_df['dx'])\nval_df['target'] = le.fit_transform(val_df['dx'])\ntest_df['target'] = le.fit_transform(test_df['dx'])","metadata":{"execution":{"iopub.status.busy":"2023-05-14T14:43:50.367327Z","iopub.execute_input":"2023-05-14T14:43:50.367743Z","iopub.status.idle":"2023-05-14T14:43:50.380325Z","shell.execute_reply.started":"2023-05-14T14:43:50.367702Z","shell.execute_reply":"2023-05-14T14:43:50.379646Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_df.target.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-05-14T14:43:50.383381Z","iopub.execute_input":"2023-05-14T14:43:50.383728Z","iopub.status.idle":"2023-05-14T14:43:50.393336Z","shell.execute_reply.started":"2023-05-14T14:43:50.383694Z","shell.execute_reply":"2023-05-14T14:43:50.392328Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"5    3497\n4     946\n2     779\n1     387\n0     217\n6      96\n3      87\nName: target, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"from collections import Counter\nfrom sklearn.utils import resample\n\n# Count the number of samples for each class\nclass_counts = Counter(train_df['target'])\n\n# Get the size of the majority class\nmajority_class_size = max(class_counts.values())\n\n# Oversample minority classes to match the size of the majority class\nfor class_label, class_size in class_counts.items():\n    if class_label != train_df['target'].mode()[0]:\n        # Determine the number of times to resample the class\n        resample_rate = int(majority_class_size / class_size)\n        \n        X_subset = train_df[train_df['target'] == class_label].drop(['target'], axis=1)\n        y_subset = train_df[train_df['target'] == class_label]['target']\n        \n        # Resample the class with replacement\n        X_subset_resampled, y_subset_resampled = resample(X_subset, y_subset, \n                                                          replace=True, n_samples=(resample_rate-1)*class_size, \n                                                          random_state=42)\n        \n        # Concatenate the resampled data with the original data\n        train_df = pd.concat([train_df, pd.concat([X_subset_resampled, y_subset_resampled], axis=1)])\n\n# Verify that all classes have the same number of samples\nprint(train_df['target'].value_counts())\n","metadata":{"execution":{"iopub.status.busy":"2023-05-14T14:43:50.394988Z","iopub.execute_input":"2023-05-14T14:43:50.395382Z","iopub.status.idle":"2023-05-14T14:43:50.738588Z","shell.execute_reply.started":"2023-05-14T14:43:50.395344Z","shell.execute_reply":"2023-05-14T14:43:50.737596Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"5    3497\n1    3483\n3    3480\n0    3472\n6    3456\n2    3116\n4    2838\nName: target, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df['sex'] = train_df['sex'].map({'male': 1, 'female': 0})\nval_df['sex'] = val_df['sex'].map({'male': 1, 'female': 0})\ntest_df['sex'] = test_df['sex'].map({'male': 1, 'female': 0})\n\ntrain_df['sex'] = train_df['sex'].fillna(-1)\nval_df['sex'] = val_df['sex'].fillna(-1)\ntest_df['sex'] = test_df['sex'].fillna(-1)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-14T14:43:50.740036Z","iopub.execute_input":"2023-05-14T14:43:50.740628Z","iopub.status.idle":"2023-05-14T14:43:50.759955Z","shell.execute_reply.started":"2023-05-14T14:43:50.740583Z","shell.execute_reply":"2023-05-14T14:43:50.759060Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"imp_mean=(train_df[\"age\"].sum())/(train_df[\"age\"].count()-train_df[\"age\"].isna().sum())\ntrain_df['age']=train_df['age'].fillna(imp_mean)\n\nimp_mean=(val_df[\"age\"].sum())/(val_df[\"age\"].count()-val_df[\"age\"].isna().sum())\nval_df['age']=val_df['age'].fillna(imp_mean)\n\nimp_mean_test=(test_df[\"age\"].sum())/(test_df[\"age\"].count()-test_df[\"age\"].isna().sum())\ntest_df['age']=test_df['age'].fillna(imp_mean_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T14:43:50.761953Z","iopub.execute_input":"2023-05-14T14:43:50.762409Z","iopub.status.idle":"2023-05-14T14:43:50.777563Z","shell.execute_reply.started":"2023-05-14T14:43:50.762365Z","shell.execute_reply":"2023-05-14T14:43:50.776743Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_df = pd.get_dummies(train_df, columns=['localization'],prefix='site')\nval_df = pd.get_dummies(val_df, columns=['localization'],prefix='site')\n\ntest_df = pd.get_dummies(test_df, columns=['localization'],prefix='site')\n\n# adding missing cols to val and test sets\nval_df = val_df.reindex(columns=train_df.columns, fill_value=0)\ntest_df = test_df.reindex(columns=train_df.columns, fill_value=0)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T14:43:50.779068Z","iopub.execute_input":"2023-05-14T14:43:50.779729Z","iopub.status.idle":"2023-05-14T14:43:50.882753Z","shell.execute_reply.started":"2023-05-14T14:43:50.779683Z","shell.execute_reply":"2023-05-14T14:43:50.881943Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# meta_features = ['sex', 'age'] + [col for col in train_df.columns if 'site_' in col]\nmeta_features = ['age', 'sex'] + [col for col in train_df.columns if 'site_' in col]","metadata":{"execution":{"iopub.status.busy":"2023-05-14T14:43:50.884102Z","iopub.execute_input":"2023-05-14T14:43:50.884548Z","iopub.status.idle":"2023-05-14T14:43:50.891035Z","shell.execute_reply.started":"2023-05-14T14:43:50.884508Z","shell.execute_reply":"2023-05-14T14:43:50.890103Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"cnn = list(range(0,256))","metadata":{"execution":{"iopub.status.busy":"2023-05-14T11:40:34.385500Z","iopub.execute_input":"2023-05-14T11:40:34.385824Z","iopub.status.idle":"2023-05-14T11:40:34.390724Z","shell.execute_reply.started":"2023-05-14T11:40:34.385767Z","shell.execute_reply":"2023-05-14T11:40:34.389790Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# cnn only\nmeta_features = cnn\n\n# meta_features = meta_features + cnn","metadata":{"execution":{"iopub.status.busy":"2023-05-14T11:40:36.685650Z","iopub.execute_input":"2023-05-14T11:40:36.686018Z","iopub.status.idle":"2023-05-14T11:40:36.690368Z","shell.execute_reply.started":"2023-05-14T11:40:36.685984Z","shell.execute_reply":"2023-05-14T11:40:36.689463Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"meta_features = [str(x) for x in meta_features]","metadata":{"execution":{"iopub.status.busy":"2023-05-14T11:40:37.279252Z","iopub.execute_input":"2023-05-14T11:40:37.279574Z","iopub.status.idle":"2023-05-14T11:40:37.284013Z","shell.execute_reply.started":"2023-05-14T11:40:37.279543Z","shell.execute_reply":"2023-05-14T11:40:37.283002Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"len(meta_features)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T14:43:50.892762Z","iopub.execute_input":"2023-05-14T14:43:50.893349Z","iopub.status.idle":"2023-05-14T14:43:50.902059Z","shell.execute_reply.started":"2023-05-14T14:43:50.893288Z","shell.execute_reply":"2023-05-14T14:43:50.901010Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"17"},"metadata":{}}]},{"cell_type":"code","source":"# meta_features","metadata":{"execution":{"iopub.status.busy":"2023-05-14T14:43:50.903695Z","iopub.execute_input":"2023-05-14T14:43:50.904393Z","iopub.status.idle":"2023-05-14T14:43:50.909101Z","shell.execute_reply.started":"2023-05-14T14:43:50.904351Z","shell.execute_reply":"2023-05-14T14:43:50.907581Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"test = MelanomaDataset(df=test_df,\n                       train=False,\n                       transforms=test_transform,\n                        meta_features=meta_features)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T14:43:50.911340Z","iopub.execute_input":"2023-05-14T14:43:50.912204Z","iopub.status.idle":"2023-05-14T14:43:50.917276Z","shell.execute_reply.started":"2023-05-14T14:43:50.912161Z","shell.execute_reply":"2023-05-14T14:43:50.916348Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self, output_size, no_columns, b1=False, b4=False):\n        super().__init__()\n        self.no_columns = no_columns\n        \n        self.b1 = b1\n        self.b4 = b4\n        \n        if self.b1:\n            self.features = EfficientNet.from_pretrained('efficientnet-b1')\n            self.classification = nn.Sequential(nn.Linear(1280 + 16, output_size))\n        elif self.b4:\n            self.features = EfficientNet.from_pretrained('efficientnet-b4')\n            self.classification = nn.Sequential(nn.Linear(1792 + 16, output_size))\n        \n        \n        # (CSV)\n        self.csv = nn.Sequential(nn.Linear(self.no_columns, 32),\n                                 nn.BatchNorm1d(32),\n                                 nn.ReLU(),\n                                 nn.Dropout(p=0.3),\n                                 \n                                 nn.Linear(32, 16),\n                                 nn.BatchNorm1d(16),\n                                 nn.ReLU(),\n                                 nn.Dropout(p=0.2))\n          \n        \n        \n    def forward(self, inputs, prints=False):    \n        \n        image, csv_data = inputs\n        \n        if prints: print('Input Image shape:', image.shape, '\\n'+\n                         'Input csv_data shape:', csv_data.shape)\n        \n        # IMAGE CNN\n        image = self.features.extract_features(image)\n        if prints: print('Features Image shape:', image.shape)\n\n        if self.b1:\n            image = F.avg_pool2d(image, image.size()[2:]).reshape(-1, 1280)\n        elif self.b4:\n            image = F.avg_pool2d(image, image.size()[2:]).reshape(-1, 1792)\n     \n        if prints: print('Image Reshaped shape:', image.shape)\n            \n        # CSV FNN\n        csv_data = self.csv(csv_data)\n        if prints: print('CSV Data:', csv_data.shape)\n            \n        # Concatenate\n        image_csv_data = torch.cat((image, csv_data), dim=1)\n        \n#         image_csv_data = F.relu(image_csv_data)\n        \n        # CLASSIF\n        out = self.classification(image_csv_data)\n        if prints: print('Out shape:', out.shape)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2023-05-14T14:43:50.918696Z","iopub.execute_input":"2023-05-14T14:43:50.919285Z","iopub.status.idle":"2023-05-14T14:43:50.938664Z","shell.execute_reply.started":"2023-05-14T14:43:50.919247Z","shell.execute_reply":"2023-05-14T14:43:50.937978Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"epochs = 3 # Number of epochs to run\nmodel_path = 'model.pth'  # Path and filename to save model to\nes_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\nTTA = 3 # Test Time Augmentation \n\noof = np.zeros((len(train_df), 7))  # Out Of Fold predictions\n","metadata":{"execution":{"iopub.status.busy":"2023-05-14T14:43:50.939886Z","iopub.execute_input":"2023-05-14T14:43:50.940485Z","iopub.status.idle":"2023-05-14T14:43:50.951050Z","shell.execute_reply.started":"2023-05-14T14:43:50.940444Z","shell.execute_reply":"2023-05-14T14:43:50.950056Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nimport tqdm.notebook as tq\nimport torch.nn.functional as F\nfrom sklearn.utils.class_weight import compute_class_weight","metadata":{"execution":{"iopub.status.busy":"2023-05-14T14:43:50.952576Z","iopub.execute_input":"2023-05-14T14:43:50.953187Z","iopub.status.idle":"2023-05-14T14:43:50.959902Z","shell.execute_reply.started":"2023-05-14T14:43:50.953150Z","shell.execute_reply":"2023-05-14T14:43:50.959059Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Define Focal loss implementation\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=2, alpha=None, reduction='mean'):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n        self.reduction = reduction\n\n    def forward(self, inputs, targets):\n        CE_loss = F.cross_entropy(inputs, targets, reduction=self.reduction, weight=self.alpha)\n        pt = torch.exp(-CE_loss)\n        F_loss = ((1-pt)**self.gamma) * CE_loss\n        if self.reduction == 'mean': return F_loss.mean()\n        else: return F_loss.sum()","metadata":{"execution":{"iopub.status.busy":"2023-05-14T14:43:50.961948Z","iopub.execute_input":"2023-05-14T14:43:50.962216Z","iopub.status.idle":"2023-05-14T14:43:50.973190Z","shell.execute_reply.started":"2023-05-14T14:43:50.962184Z","shell.execute_reply":"2023-05-14T14:43:50.972551Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"best_val = None  # Best validation score within this fold\npatience = es_patience  # Current patience counter\n#     arch = EfficientNet.from_pretrained('efficientnet-b1')\n#     arch = models.resnet50(pretrained=True)\n#     model = Net(arch=arch, n_meta_features=len(meta_features))  # New model for each fold\n\nmodel = Net(output_size = 7 , no_columns=len(meta_features), b4=True)\nmodel = model.to(device)\n\n\noptim = torch.optim.Adam(model.parameters(), lr=0.0001)\nscheduler = ReduceLROnPlateau(optimizer=optim, mode='max', patience=1, verbose=True, factor=0.4)\n\n\n# Get the class weights for the training data\n#class_weights1 = torch.tensor(compute_class_weight('balanced', classes=np.unique(train_df.iloc[train_idx]['target']), y=train_df.iloc[train_idx]['target']), dtype=torch.float32)\n#class_weights = class_weights1.to(device)\n\n#giving more importance to mel\n\n# Define weight factors\nclass_factor_interest = 2.0\nclass_factor_minority = 1.0\nclass_factor_majority = 0.5\n\n# Get class labels and weights\nclass_labels = np.unique(train_df['target'])\nclass_weights_all = compute_class_weight('balanced', classes=class_labels, y=train_df['target'])\n\n# Modify class weights to reflect weight factors\nclass_weights = np.zeros_like(class_weights_all)\nfor i, weight in enumerate(class_weights_all):\n    if class_labels[i] == 4:  # class of interest\n        class_weights[i] = weight * class_factor_interest\n    elif weight == np.max(class_weights_all):  # majority class\n        class_weights[i] = weight * class_factor_majority\n    else:  # minority class\n        class_weights[i] = weight * class_factor_minority\n\n# Convert class weights to PyTorch tensor\nclass_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n\n\n\nfocal_loss = FocalLoss(gamma=2, alpha=class_weights)\ncriterion = nn.CrossEntropyLoss(weight = class_weights)\n\ntrain = MelanomaDataset(df=train_df.reset_index(drop=True), \n                        train=True, \n                        transforms=train_transform,\n                        meta_features=meta_features)\nval = MelanomaDataset(df=val_df.reset_index(drop=True), \n                        train=True, \n                        transforms=test_transform,\n                        meta_features=meta_features)   \n\ntrain_loader = DataLoader(dataset=train, batch_size=8, shuffle=True, num_workers=0, drop_last=True)\nval_loader = DataLoader(dataset=val, batch_size=4, shuffle=False, num_workers=0, drop_last=True)\ntest_loader = DataLoader(dataset=test, batch_size=4, shuffle=False, num_workers=0)\n\nfor epoch in tqdm(range(epochs)):\n    start_time = time.time()\n    correct = 0\n    epoch_loss = 0\n    model.train()\n\n    for x, y in tq.tqdm(train_loader):\n        x[0] = torch.tensor(x[0], device=device, dtype=torch.float32)\n        x[1] = torch.tensor(x[1], device=device, dtype=torch.float32)\n        y = torch.tensor(y, device=device, dtype=torch.long)\n\n        optim.zero_grad()\n#             z = model(x)\n        z = model(x)\n#         loss = focal_loss(z, y)\n        loss = criterion(z, y)\n        loss.backward()\n        optim.step()\n        pred = torch.argmax(z, dim=1)  # get the index of the highest value in out\n        correct += (pred.cpu() == y.cpu()).sum().item()  # tracking number of correctly predicted samples\n        epoch_loss += loss.item()\n    train_acc = correct / len(train_df)\n\n    model.eval()  # switch model to the evaluation mode\n    val_preds = torch.zeros((len(val_df), 7), dtype=torch.float32, device=device)\n    with torch.no_grad():  # Do not calculate gradient since we are only predicting\n        # Predicting on validation set\n        for j, (x_val, y_val) in enumerate(val_loader):\n            x_val[0] = torch.tensor(x_val[0], device=device, dtype=torch.float32)\n            x_val[1] = torch.tensor(x_val[1], device=device, dtype=torch.float32)\n            y_val = torch.tensor(y_val, device=device, dtype=torch.long)\n#                 z_val = model(x_val)\n            z_val = model(x_val)\n            val_pred = torch.sigmoid(z_val)\n            val_preds[j*x_val[0].shape[0]:j*x_val[0].shape[0] + x_val[0].shape[0]] = val_pred\n\n        val_preds = torch.softmax(val_preds, dim=1) # use softmax to convert logits to probabilities\n        val_acc = accuracy_score(val_df['target'].values, torch.argmax(val_preds.cpu(), dim=1))\n        val_preds = val_preds.cpu().detach().numpy()\n        val_preds = val_preds.reshape(-1, 7) # reshape val_preds to a 2D tensor\n\n        val_roc = roc_auc_score(val_df['target'].values, val_preds, multi_class='ovr')\n\n        print('Epoch {:03}: | Loss: {:.3f} | Train acc: {:.3f} | Val acc: {:.3f} | Val roc_auc: {:.3f} | Training time: {}'.format(\n        epoch + 1, \n        epoch_loss/len(train_loader), \n        train_acc, \n        val_acc, \n        val_roc, \n        str(datetime.timedelta(seconds=time.time() - start_time))[:7]))\n\n        scheduler.step(val_roc)\n        # During the first iteration (first epoch) best validation is set to None\n        if not best_val:\n            best_val = val_roc  # So any validation roc_auc we have is the best one for now\n            torch.save(model, model_path)  # Saving the model\n            continue\n\n        if val_roc >= best_val:\n            best_val = val_roc\n            patience = es_patience  # Resetting patience since we have new best validation accuracy\n            torch.save(model, model_path)  # Saving current best model\n        else:\n            patience -= 1\n            if patience == 0:\n                print('Early stopping. Best Val roc_auc: {:.3f}'.format(best_val))\n                break\n","metadata":{"execution":{"iopub.status.busy":"2023-05-14T14:43:50.974574Z","iopub.execute_input":"2023-05-14T14:43:50.975164Z","iopub.status.idle":"2023-05-14T16:20:59.835347Z","shell.execute_reply.started":"2023-05-14T14:43:50.975127Z","shell.execute_reply":"2023-05-14T16:20:59.834407Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b4-6ed6700e.pth\" to /root/.cache/torch/checkpoints/efficientnet-b4-6ed6700e.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=77999237.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55e49e6466164feca25f0bfe0c8e59b5"}},"metadata":{}},{"name":"stdout","text":"\nLoaded pretrained weights for efficientnet-b4\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/3 [00:00<?, ?it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=2917.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb1eeb5a7f8d4fae946c60747aadbcfa"}},"metadata":{}},{"name":"stdout","text":"\nEpoch 001: | Loss: 0.495 | Train acc: 0.828 | Val acc: 0.919 | Val roc_auc: 0.969 | Training time: 0:33:25\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 1/3 [33:25<1:06:51, 2005.96s/it]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=2917.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19ec52a7d34946b9a08cee7d1c766b34"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 2/3 [1:05:08<32:55, 1975.03s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 002: | Loss: 0.172 | Train acc: 0.945 | Val acc: 0.923 | Val roc_auc: 0.944 | Training time: 0:31:42\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=2917.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0e44f8b1c8147f588bc8464e2208570"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3/3 [1:37:00<00:00, 1940.28s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 003: | Loss: 0.106 | Train acc: 0.967 | Val acc: 0.917 | Val roc_auc: 0.951 | Training time: 0:31:52\nEpoch     3: reducing learning rate of group 0 to 4.0000e-05.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"test_loader = DataLoader(dataset=test, batch_size=4, shuffle=False,num_workers=0)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T16:20:59.836914Z","iopub.execute_input":"2023-05-14T16:20:59.837526Z","iopub.status.idle":"2023-05-14T16:20:59.843065Z","shell.execute_reply.started":"2023-05-14T16:20:59.837483Z","shell.execute_reply":"2023-05-14T16:20:59.841934Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"test_df.dx.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-05-14T16:20:59.844626Z","iopub.execute_input":"2023-05-14T16:20:59.845265Z","iopub.status.idle":"2023-05-14T16:20:59.859460Z","shell.execute_reply.started":"2023-05-14T16:20:59.845226Z","shell.execute_reply":"2023-05-14T16:20:59.858587Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"nv       1604\nbkl       160\nmel        83\nbcc        64\nakiec      55\nvasc       23\ndf         14\nName: dx, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"import gc\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-05-14T16:20:59.862665Z","iopub.execute_input":"2023-05-14T16:20:59.863025Z","iopub.status.idle":"2023-05-14T16:21:00.276391Z","shell.execute_reply.started":"2023-05-14T16:20:59.862996Z","shell.execute_reply":"2023-05-14T16:21:00.275288Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"model = torch.load('/kaggle/working/model.pth')\nmodel.eval()  # switch model to the evaluation mode\npreds = torch.zeros((len(test), 7), dtype=torch.float32, device=device)\nwith torch.no_grad():\n\n    for i, x_test in enumerate(test_loader):\n        x_test[0] = torch.tensor(x_test[0], device=device, dtype=torch.float32)\n        x_test[1] = torch.tensor(x_test[1], device=device, dtype=torch.float32)\n#         z_test = model(x_test)\n        z_test = model(x_test)\n        z_test = torch.softmax(z_test, dim=1) # use softmax to convert logits to probabilities\n        preds[i*x_test[0].shape[0]:i*x_test[0].shape[0] + x_test[0].shape[0]] += z_test\n\n\n\ngc.collect()   \n           \n","metadata":{"execution":{"iopub.status.busy":"2023-05-14T16:21:00.278387Z","iopub.execute_input":"2023-05-14T16:21:00.279058Z","iopub.status.idle":"2023-05-14T16:22:26.714241Z","shell.execute_reply.started":"2023-05-14T16:21:00.278984Z","shell.execute_reply":"2023-05-14T16:22:26.713357Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score,recall_score, f1_score\n\nfrom sklearn.preprocessing import LabelBinarizer\n\n# Convert the target data to one-hot encoded format\nlb = LabelBinarizer()\ntest_labels = lb.fit_transform(test_df['target'])\n\n# Get predictions for the test set\ntest_preds = preds.cpu()\n\n# Convert the predictions to one-hot encoded format if needed\nif len(test_preds.shape) > 1 and test_preds.shape[1] > 1:\n    test_preds = np.argmax(test_preds, axis=1)\n    test_preds = lb.transform(test_preds)\n\n# Calculate metrics\nacc = accuracy_score(test_labels, test_preds)\nprec = precision_score(test_labels, test_preds, average='macro')\nrec = recall_score(test_labels, test_preds, average='macro')\nf1 = f1_score(test_labels, test_preds, average='macro')\nroc = roc_auc_score(test_labels, test_preds, multi_class='ovr')\n","metadata":{"execution":{"iopub.status.busy":"2023-05-14T16:22:26.715647Z","iopub.execute_input":"2023-05-14T16:22:26.716023Z","iopub.status.idle":"2023-05-14T16:22:26.752977Z","shell.execute_reply.started":"2023-05-14T16:22:26.715985Z","shell.execute_reply":"2023-05-14T16:22:26.752175Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"print(\"acc \", acc)\nprint(\"prec \",prec)\nprint(\"rec \",rec)\nprint(\"f1 \",f1)\nprint(\"roc \",roc)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T16:22:26.754367Z","iopub.execute_input":"2023-05-14T16:22:26.754744Z","iopub.status.idle":"2023-05-14T16:22:26.761484Z","shell.execute_reply.started":"2023-05-14T16:22:26.754706Z","shell.execute_reply":"2023-05-14T16:22:26.760016Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"acc  0.9181228157763355\nprec  0.7576778264488081\nrec  0.7548960541720126\nf1  0.7474655607370061\nroc  0.8645995976890198\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Generate the confusion matrix\nconf_matrix = confusion_matrix(test_labels.argmax(axis=1), test_preds.argmax(axis=1))\n\n# Create a heatmap of the confusion matrix\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n\n# Set the axis labels and title\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title('Confusion Matrix')\n\n# Display the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-14T16:22:26.763355Z","iopub.execute_input":"2023-05-14T16:22:26.763958Z","iopub.status.idle":"2023-05-14T16:22:27.147200Z","shell.execute_reply.started":"2023-05-14T16:22:26.763917Z","shell.execute_reply":"2023-05-14T16:22:27.146357Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"# Extract the row and column corresponding to class 4: mel\nclass_idx = 4\nfn = conf_matrix[class_idx, :].sum() - conf_matrix[class_idx, class_idx]\n\n# Calculate the percentage of instances from class 4 that were classified as another class\nfn_percent = (fn / conf_matrix[class_idx, :].sum()) * 100\n\n# Print the results\nprint(f\"False Negative Rate for mel: {fn_percent:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2023-05-14T16:22:27.150914Z","iopub.execute_input":"2023-05-14T16:22:27.151198Z","iopub.status.idle":"2023-05-14T16:22:27.160469Z","shell.execute_reply.started":"2023-05-14T16:22:27.151169Z","shell.execute_reply":"2023-05-14T16:22:27.159364Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"False Negative Rate for mel: 59.04%\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}