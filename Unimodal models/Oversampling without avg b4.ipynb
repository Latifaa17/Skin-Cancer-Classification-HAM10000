{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### Versions:\n* v9: ColorJitter transformation added\n* v10: Changed the dataset to [this one](https://www.kaggle.com/shonenkov/melanoma-merged-external-data-512x512-jpeg) with external data.\n* v11: Switched to [another dataset](https://www.kaggle.com/nroman/melanoma-external-malignant-256/) which I've created by myself. Also switched from StratifiedKFold to GroupKFold\n* v12: Switched to efficientnet-b1","metadata":{}},{"cell_type":"code","source":"!pip install efficientnet_pytorch torchtoolbox","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-05-13T23:01:38.153202Z","iopub.execute_input":"2023-05-13T23:01:38.153905Z","iopub.status.idle":"2023-05-13T23:01:48.988273Z","shell.execute_reply.started":"2023-05-13T23:01:38.153854Z","shell.execute_reply":"2023-05-13T23:01:48.987274Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting efficientnet_pytorch\n  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\nCollecting torchtoolbox\n  Downloading torchtoolbox-0.1.8.2-py3-none-any.whl (84 kB)\n\u001b[K     |████████████████████████████████| 84 kB 2.4 MB/s eta 0:00:011\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet_pytorch) (1.5.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (4.45.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (1.18.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (1.14.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (2.9.0)\nRequirement already satisfied: prettytable in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (0.7.2)\nCollecting lmdb\n  Downloading lmdb-1.4.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (294 kB)\n\u001b[K     |████████████████████████████████| 294 kB 52.5 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: pyarrow in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (0.16.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (5.3.1)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (1.4.1)\nRequirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (4.2.0.34)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (0.22.2.post1)\nRequirement already satisfied: tensorboard in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (2.1.1)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet_pytorch) (0.18.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers->torchtoolbox) (3.0.10)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers->torchtoolbox) (2020.4.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers->torchtoolbox) (2.23.0)\nRequirement already satisfied: tokenizers==0.7.0 in /opt/conda/lib/python3.7/site-packages (from transformers->torchtoolbox) (0.7.0)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers->torchtoolbox) (0.0.43)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from transformers->torchtoolbox) (0.1.86)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->torchtoolbox) (0.14.1)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (1.14.0)\nRequirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (3.11.4)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (0.4.1)\nRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (0.34.2)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (1.0.1)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (46.1.3.post20200325)\nRequirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (1.28.1)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (0.9.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (3.2.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers->torchtoolbox) (2020.4.5.1)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers->torchtoolbox) (2.9)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers->torchtoolbox) (1.24.3)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers->torchtoolbox) (3.0.4)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers->torchtoolbox) (7.1.1)\nRequirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->torchtoolbox) (4.0)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->torchtoolbox) (3.1.1)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->torchtoolbox) (0.2.7)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->torchtoolbox) (1.2.0)\nRequirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard->torchtoolbox) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->torchtoolbox) (3.0.1)\nBuilding wheels for collected packages: efficientnet-pytorch\n  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=ba56680baa6e66225f71cf70995c9d669d39ce9efe37e5015d2def8f5216e582\n  Stored in directory: /root/.cache/pip/wheels/0e/cc/b2/49e74588263573ff778da58cc99b9c6349b496636a7e165be6\nSuccessfully built efficientnet-pytorch\nInstalling collected packages: efficientnet-pytorch, lmdb, torchtoolbox\nSuccessfully installed efficientnet-pytorch-0.7.1 lmdb-1.4.1 torchtoolbox-0.1.8.2\n\u001b[33mWARNING: You are using pip version 20.1; however, version 23.1.2 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torchvision\nfrom torchvision import models,transforms\n\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold\nimport pandas as pd\nimport numpy as np\nimport gc\nimport os\nimport cv2\nimport time\nimport datetime\nimport warnings\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom efficientnet_pytorch import EfficientNet\n\nfrom sklearn.model_selection import train_test_split\n\nimport torch.nn.functional as F\n\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-13T23:01:48.990665Z","iopub.execute_input":"2023-05-13T23:01:48.991054Z","iopub.status.idle":"2023-05-13T23:01:51.665079Z","shell.execute_reply.started":"2023-05-13T23:01:48.991011Z","shell.execute_reply":"2023-05-13T23:01:51.664280Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# At least fixing some random seeds. \n# It is still impossible to make results 100% reproducible when using GPU\nwarnings.simplefilter('ignore')\ntorch.manual_seed(47)\nnp.random.seed(47)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:01:51.666511Z","iopub.execute_input":"2023-05-13T23:01:51.666861Z","iopub.status.idle":"2023-05-13T23:01:51.673675Z","shell.execute_reply.started":"2023-05-13T23:01:51.666822Z","shell.execute_reply":"2023-05-13T23:01:51.672833Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:01:51.674991Z","iopub.execute_input":"2023-05-13T23:01:51.675662Z","iopub.status.idle":"2023-05-13T23:01:51.703157Z","shell.execute_reply.started":"2023-05-13T23:01:51.675519Z","shell.execute_reply":"2023-05-13T23:01:51.702332Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class MelanomaDataset(Dataset):\n    def __init__(self, df: pd.DataFrame, train: bool = True, transforms = None):\n        \"\"\"\n        Class initialization\n        Args:\n            df (pd.DataFrame): DataFrame with data description\n            imfolder (str): folder with images\n            train (bool): flag of whether a training dataset is being initialized or testing one\n            transforms: image transformation method to be applied\n            \n        \"\"\"\n        self.df = df\n        self.path1 = '/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1'\n        self.path2 = '/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2'\n        self.transforms = transforms\n        self.train = train\n        \n    def __getitem__(self, index):\n        \n        image_path = os.path.join(self.path1, self.df.iloc[index]['image_id'] + '.jpg')\n        if os.path.exists(image_path):\n            image = cv2.imread(image_path)\n        else:\n            # If the image is not in part 1, try to load it from part 2\n            image_path = os.path.join(self.path2, self.df.iloc[index]['image_id'] + '.jpg')\n            if os.path.exists(image_path):\n                image = cv2.imread(image_path)\n\n        if self.transforms:\n            x = self.transforms(image)\n            \n        if self.train:\n            y = self.df.loc[index]['target']\n            return x, y\n        else:\n            return x\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def _get_label(self, dataset, idx):\n        return self.df.iloc[idx]['target']\n    \n    \n","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:01:51.707485Z","iopub.execute_input":"2023-05-13T23:01:51.708224Z","iopub.status.idle":"2023-05-13T23:01:51.722752Z","shell.execute_reply.started":"2023-05-13T23:01:51.708181Z","shell.execute_reply":"2023-05-13T23:01:51.722021Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.ToPILImage(),\n    #transforms.RandomResizedCrop(size=240, scale=(0.8, 1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n])\ntest_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n])\n","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:01:51.724689Z","iopub.execute_input":"2023-05-13T23:01:51.724983Z","iopub.status.idle":"2023-05-13T23:01:51.735916Z","shell.execute_reply.started":"2023-05-13T23:01:51.724955Z","shell.execute_reply":"2023-05-13T23:01:51.735109Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv')\n\n\n# this will tell us how many images are associated with each lesion_id\ndf_undup = df.groupby('lesion_id').count()\n# now we filter out lesion_id's that have only one image associated with it\ndf_undup = df_undup[df_undup['image_id'] == 1]\ndf_undup.reset_index(inplace=True)\n\ndef get_duplicates(x):\n    unique_list = list(df_undup['lesion_id'])\n    if x in unique_list:\n        return 'unduplicated'\n    else:\n        return 'duplicated'\n\n# create a new colum that is a copy of the lesion_id column\ndf['duplicates'] = df['lesion_id']\n# apply the function to this new column\ndf['duplicates'] = df['duplicates'].apply(get_duplicates)\n\ndf_undup  = df[df['duplicates'] == 'unduplicated']\n\n#now we create a test set using df_undup because we are sure that none of these images have augmented duplicates in the train set\ny = df_undup['dx']\n_, test_df_csv = train_test_split(df_undup, test_size=0.7265, random_state=101, stratify=y)\ntest_df_csv.shape\n\n# This set will be df_original excluding all rows that are in the test set\n# This function identifies if an image is part of the train or test set.\ndef get_test_rows(x):\n    # create a list of all the lesion_id's in the val test\n    test_list = list(test_df_csv['image_id'])\n    if str(x) in test_list:\n        return 'test'\n    else:\n        return 'train'\n\n# identify train and test rows\n# create a new colum that is a copy of the image_id column\ndf['train_or_test'] = df['image_id']\n# apply the function to this new column\ndf['train_or_test'] = df['train_or_test'].apply(get_test_rows)\n# filter out train rows\ntrain_df_csv = df[df['train_or_test'] == 'train']\n\n# Split the test into 50% test and 50% validation\ntest_df, val_df = train_test_split(test_df_csv, test_size=0.5, random_state=101, stratify=test_df_csv['dx'])\n\ntrain_df = train_df_csv\nprint(len(train_df))\nprint(len(val_df))\nprint(len(test_df))","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:02:23.116668Z","iopub.execute_input":"2023-05-13T23:02:23.117029Z","iopub.status.idle":"2023-05-13T23:02:36.483869Z","shell.execute_reply.started":"2023-05-13T23:02:23.116996Z","shell.execute_reply":"2023-05-13T23:02:36.482818Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"6009\n2003\n2003\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df.dx.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:02:36.485849Z","iopub.execute_input":"2023-05-13T23:02:36.486177Z","iopub.status.idle":"2023-05-13T23:02:36.498427Z","shell.execute_reply.started":"2023-05-13T23:02:36.486146Z","shell.execute_reply":"2023-05-13T23:02:36.497284Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"nv       3497\nmel       946\nbkl       779\nbcc       387\nakiec     217\nvasc       96\ndf         87\nName: dx, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ntrain_df['target'] = le.fit_transform(train_df['dx'])\nval_df['target'] = le.fit_transform(val_df['dx'])\ntest_df['target'] = le.fit_transform(test_df['dx'])","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:02:36.500633Z","iopub.execute_input":"2023-05-13T23:02:36.501082Z","iopub.status.idle":"2023-05-13T23:02:36.517692Z","shell.execute_reply.started":"2023-05-13T23:02:36.501013Z","shell.execute_reply":"2023-05-13T23:02:36.516855Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_df.target.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:02:36.520036Z","iopub.execute_input":"2023-05-13T23:02:36.520477Z","iopub.status.idle":"2023-05-13T23:02:36.529964Z","shell.execute_reply.started":"2023-05-13T23:02:36.520438Z","shell.execute_reply":"2023-05-13T23:02:36.529103Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"5    3497\n4     946\n2     779\n1     387\n0     217\n6      96\n3      87\nName: target, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"from collections import Counter\nfrom sklearn.utils import resample\n\n# Count the number of samples for each class\nclass_counts = Counter(train_df['target'])\n\n# Get the size of the majority class\nmajority_class_size = max(class_counts.values())\n\n# Oversample minority classes to match the size of the majority class\nfor class_label, class_size in class_counts.items():\n    if class_label != train_df['target'].mode()[0]:\n        # Determine the number of times to resample the class\n        resample_rate = int(majority_class_size / class_size)\n        \n        X_subset = train_df[train_df['target'] == class_label].drop(['target'], axis=1)\n        y_subset = train_df[train_df['target'] == class_label]['target']\n        \n        # Resample the class with replacement\n        X_subset_resampled, y_subset_resampled = resample(X_subset, y_subset, \n                                                          replace=True, n_samples=(resample_rate-1)*class_size, \n                                                          random_state=42)\n        \n        # Concatenate the resampled data with the original data\n        train_df = pd.concat([train_df, pd.concat([X_subset_resampled, y_subset_resampled], axis=1)])\n\n# Verify that all classes have the same number of samples\nprint(train_df['target'].value_counts())\n","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:02:45.528370Z","iopub.execute_input":"2023-05-13T23:02:45.528729Z","iopub.status.idle":"2023-05-13T23:02:45.621667Z","shell.execute_reply.started":"2023-05-13T23:02:45.528694Z","shell.execute_reply":"2023-05-13T23:02:45.620738Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"5    3497\n1    3483\n3    3480\n0    3472\n6    3456\n2    3116\n4    2838\nName: target, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df['sex'] = train_df['sex'].map({'male': 1, 'female': 0})\nval_df['sex'] = val_df['sex'].map({'male': 1, 'female': 0})\ntest_df['sex'] = test_df['sex'].map({'male': 1, 'female': 0})\n\ntrain_df['sex'] = train_df['sex'].fillna(-1)\nval_df['sex'] = val_df['sex'].fillna(-1)\ntest_df['sex'] = test_df['sex'].fillna(-1)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:02:47.334859Z","iopub.execute_input":"2023-05-13T23:02:47.335245Z","iopub.status.idle":"2023-05-13T23:02:47.353718Z","shell.execute_reply.started":"2023-05-13T23:02:47.335205Z","shell.execute_reply":"2023-05-13T23:02:47.352798Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_df = pd.get_dummies(train_df, columns=['localization'],prefix='site')\nval_df = pd.get_dummies(val_df, columns=['localization'],prefix='site')\n\ntest_df = pd.get_dummies(test_df, columns=['localization'],prefix='site')\n\n# adding missing cols to val and test sets\nval_df = val_df.reindex(columns=train_df.columns, fill_value=0)\ntest_df = test_df.reindex(columns=train_df.columns, fill_value=0)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:02:47.631160Z","iopub.execute_input":"2023-05-13T23:02:47.631505Z","iopub.status.idle":"2023-05-13T23:02:47.665402Z","shell.execute_reply.started":"2023-05-13T23:02:47.631473Z","shell.execute_reply":"2023-05-13T23:02:47.664485Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"test = MelanomaDataset(df=test_df,\n                       train=False,\n                       transforms=test_transform)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:02:48.121282Z","iopub.execute_input":"2023-05-13T23:02:48.121641Z","iopub.status.idle":"2023-05-13T23:02:48.126316Z","shell.execute_reply.started":"2023-05-13T23:02:48.121606Z","shell.execute_reply":"2023-05-13T23:02:48.125222Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"    \nclass Net(nn.Module):\n    def __init__(self,b1 = False, b4 = False):\n        super(Net, self).__init__()\n        self.b1 = b1\n        self.b4 = b4\n        if self.b1:\n            self.arch = EfficientNet.from_pretrained('efficientnet-b1')\n            self.arch._fc = nn.Linear(in_features=1280, out_features=7, bias=True)\n            \n        elif self.b4:\n            self.arch = EfficientNet.from_pretrained('efficientnet-b4')\n            self.arch._fc = nn.Linear(in_features=1792, out_features=7, bias=True)\n\n        \n    def forward(self, x):\n        x = self.arch(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:02:48.552955Z","iopub.execute_input":"2023-05-13T23:02:48.553346Z","iopub.status.idle":"2023-05-13T23:02:48.562548Z","shell.execute_reply.started":"2023-05-13T23:02:48.553311Z","shell.execute_reply":"2023-05-13T23:02:48.561409Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self,b1 = False, b4 = False):\n        super(Net, self).__init__()\n        self.b1 = b1\n        self.b4 = b4\n        \n        if self.b1:\n            self.features = EfficientNet.from_pretrained('efficientnet-b1')\n            self.classification = nn.Sequential(nn.Linear(1280, 7))  \n        elif self.b4:\n            self.features = EfficientNet.from_pretrained('efficientnet-b4')\n            self.classification = nn.Sequential(nn.Linear(1792, 7))  \n\n        \n    def forward(self, x):\n        x = self.features.extract_features(x)\n        \n        if self.b1:\n            x = F.avg_pool2d(x, x.size()[2:]).reshape(-1, 1280)\n        elif self.b4:\n            x = F.avg_pool2d(x, x.size()[2:]).reshape(-1, 1792)       \n        \n        out = self.classification(x)\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:02:50.520494Z","iopub.execute_input":"2023-05-13T23:02:50.520861Z","iopub.status.idle":"2023-05-13T23:02:50.532180Z","shell.execute_reply.started":"2023-05-13T23:02:50.520828Z","shell.execute_reply":"2023-05-13T23:02:50.531265Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"epochs = 3  # Number of epochs to run\nmodel_path = 'model.pth'  # Path and filename to save model to\nes_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\nTTA = 3 # Test Time Augmentation \n\noof = np.zeros((len(train_df), 7))  # Out Of Fold predictions\n","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:02:56.837441Z","iopub.execute_input":"2023-05-13T23:02:56.837790Z","iopub.status.idle":"2023-05-13T23:02:56.843521Z","shell.execute_reply.started":"2023-05-13T23:02:56.837758Z","shell.execute_reply":"2023-05-13T23:02:56.842313Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nimport tqdm.notebook as tq\nimport torch.nn.functional as F\nfrom sklearn.utils.class_weight import compute_class_weight","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:02:57.556697Z","iopub.execute_input":"2023-05-13T23:02:57.557039Z","iopub.status.idle":"2023-05-13T23:02:57.562881Z","shell.execute_reply.started":"2023-05-13T23:02:57.557006Z","shell.execute_reply":"2023-05-13T23:02:57.561913Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Define Focal loss implementation\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=2, alpha=None, reduction='mean'):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n        self.reduction = reduction\n\n    def forward(self, inputs, targets):\n        CE_loss = F.cross_entropy(inputs, targets, reduction=self.reduction, weight=self.alpha)\n        pt = torch.exp(-CE_loss)\n        F_loss = ((1-pt)**self.gamma) * CE_loss\n        if self.reduction == 'mean': return F_loss.mean()\n        else: return F_loss.sum()","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:02:58.663427Z","iopub.execute_input":"2023-05-13T23:02:58.663770Z","iopub.status.idle":"2023-05-13T23:02:58.674116Z","shell.execute_reply.started":"2023-05-13T23:02:58.663737Z","shell.execute_reply":"2023-05-13T23:02:58.672895Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"\nbest_val = None  # Best validation score within this fold\npatience = es_patience  # Current patience counter\n#     arch = EfficientNet.from_pretrained('efficientnet-b1')\n#     arch = models.resnet50(pretrained=True)\n\n\nmodel = Net(b4=True)  # New model for each fold\nmodel = model.to(device)\n\n#giving more importance to mel\n\n# Define weight factors\nclass_factor_interest = 2.0\nclass_factor_minority = 1.0\nclass_factor_majority = 0.5\n\n# Get class labels and weights\nclass_labels = np.unique(train_df['target'])\nclass_weights_all = compute_class_weight('balanced', classes=class_labels, y=train_df['target'])\n\n# Modify class weights to reflect weight factors\nclass_weights = np.zeros_like(class_weights_all)\nfor i, weight in enumerate(class_weights_all):\n    if class_labels[i] == 4:  # class of interest\n        class_weights[i] = weight * class_factor_interest\n    elif weight == np.max(class_weights_all):  # majority class\n        class_weights[i] = weight * class_factor_majority\n    else:  # minority class\n        class_weights[i] = weight * class_factor_minority\n\n# Convert class weights to PyTorch tensor\nclass_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n\n# Initialize Focal loss object\nfocal_loss = FocalLoss(gamma=2, alpha=class_weights)\n\n\noptim = torch.optim.Adam(model.parameters(), lr=0.0001)\nscheduler = ReduceLROnPlateau(optimizer=optim, mode='max', patience=1, verbose=True, factor=0.4)\ncriterion = nn.CrossEntropyLoss(weight=class_weights)\n\ntrain = MelanomaDataset(df=train_df.reset_index(drop=True), \n                        train=True, \n                        transforms=train_transform)\nval = MelanomaDataset(df=val_df.reset_index(drop=True), \n                        train=True, \n                        transforms=test_transform)\n\ntrain_loader = DataLoader(dataset=train, batch_size=8, shuffle=True, num_workers=0)\nval_loader = DataLoader(dataset=val, batch_size=4, shuffle=False, num_workers=0)\ntest_loader = DataLoader(dataset=test, batch_size=4, shuffle=False, num_workers=0)\n\nfor epoch in tqdm(range(epochs)):\n    start_time = time.time()\n    correct = 0\n    epoch_loss = 0\n    model.train()\n\n    for x, y in tq.tqdm(train_loader):\n        x = torch.tensor(x, device=device, dtype=torch.float32)\n        y = torch.tensor(y, device=device, dtype=torch.long)\n        optim.zero_grad()\n        z = model(x)\n#         loss =  focal_loss(z, y)\n        loss =  criterion(z, y)\n        loss.backward()\n        optim.step()\n        pred = torch.argmax(z, dim=1)  # get the index of the highest value in out\n        correct += (pred.cpu() == y.cpu()).sum().item()  # tracking number of correctly predicted samples\n        epoch_loss += loss.item()\n    train_acc = correct / len(train_df)\n\n    model.eval()  # switch model to the evaluation mode\n    val_preds = torch.zeros((len(val_df), 7), dtype=torch.float32, device=device)\n    with torch.no_grad():  # Do not calculate gradient since we are only predicting\n        # Predicting on validation set\n        for j, (x_val, y_val) in enumerate(val_loader):\n            x_val = torch.tensor(x_val, device=device, dtype=torch.float32)\n            y_val = torch.tensor(y_val, device=device, dtype=torch.long)\n            z_val = model(x_val)\n            val_pred = torch.softmax(z_val, dim=1) # use softmax to convert logits to probabilities\n            val_preds[j*x_val.shape[0]:j*x_val.shape[0] + x_val.shape[0]] = val_pred\n\n        val_preds = torch.softmax(val_preds, dim=1) # use softmax to convert logits to probabilities\n        val_acc = accuracy_score(val_df['target'].values, torch.argmax(val_preds.cpu(), dim=1))\n        val_preds = val_preds.cpu().detach().numpy()\n        val_preds = val_preds.reshape(-1, 7) # reshape val_preds to a 2D tensor\n\n        val_roc = roc_auc_score(val_df['target'].values, val_preds, multi_class='ovr')\n\n\n        print('Epoch {:03}: | Loss: {:.3f} | Train acc: {:.3f} | Val acc: {:.3f} | Val roc_auc: {:.3f} | Training time: {}'.format(\n        epoch + 1, \n        epoch_loss/len(train_loader), \n        train_acc, \n        val_acc, \n        val_roc, \n        str(datetime.timedelta(seconds=time.time() - start_time))[:7]))\n\n        scheduler.step(val_roc)\n        # During the first iteration (first epoch) best validation is set to None\n        if not best_val:\n            best_val = val_roc  # So any validation roc_auc we have is the best one for now\n            torch.save(model, model_path)  # Saving the model\n            continue\n\n        if val_roc >= best_val:\n            best_val = val_roc\n            patience = es_patience  # Resetting patience since we have new best validation accuracy\n            torch.save(model, model_path)  # Saving current best model\n        else:\n            patience -= 1\n            if patience == 0:\n                print('Early stopping. Best Val roc_auc: {:.3f}'.format(best_val))\n                break\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:03:30.189768Z","iopub.execute_input":"2023-05-13T23:03:30.190142Z","iopub.status.idle":"2023-05-14T00:37:55.942279Z","shell.execute_reply.started":"2023-05-13T23:03:30.190104Z","shell.execute_reply":"2023-05-14T00:37:55.941309Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b4-6ed6700e.pth\" to /root/.cache/torch/checkpoints/efficientnet-b4-6ed6700e.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=77999237.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b003749a7d4a463297853feb2dcc2a78"}},"metadata":{}},{"name":"stdout","text":"\nLoaded pretrained weights for efficientnet-b4\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/3 [00:00<?, ?it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=2918.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"765d4692c6424f2da6e6d6b9a2da1de6"}},"metadata":{}},{"name":"stdout","text":"\nEpoch 001: | Loss: 0.496 | Train acc: 0.829 | Val acc: 0.890 | Val roc_auc: 0.975 | Training time: 0:32:17\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 1/3 [32:18<1:04:36, 1938.15s/it]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=2918.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07d14319533a4c48a1dd7b314edcb0a9"}},"metadata":{}},{"name":"stdout","text":"\nEpoch 002: | Loss: 0.185 | Train acc: 0.941 | Val acc: 0.915 | Val roc_auc: 0.982 | Training time: 0:31:02\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 2/3 [1:03:20<31:55, 1915.48s/it]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=2918.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0f50d3db3764b398178cddacb9f6414"}},"metadata":{}},{"name":"stdout","text":"\nEpoch 003: | Loss: 0.108 | Train acc: 0.965 | Val acc: 0.933 | Val roc_auc: 0.985 | Training time: 0:30:59\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3/3 [1:34:20<00:00, 1886.68s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"test_loader = DataLoader(dataset=test, batch_size=4, shuffle=False,num_workers=0)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T00:37:55.944253Z","iopub.execute_input":"2023-05-14T00:37:55.944811Z","iopub.status.idle":"2023-05-14T00:37:55.949913Z","shell.execute_reply.started":"2023-05-14T00:37:55.944765Z","shell.execute_reply":"2023-05-14T00:37:55.949175Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"test_df.dx.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-05-14T00:37:55.951706Z","iopub.execute_input":"2023-05-14T00:37:55.952097Z","iopub.status.idle":"2023-05-14T00:37:55.969688Z","shell.execute_reply.started":"2023-05-14T00:37:55.952040Z","shell.execute_reply":"2023-05-14T00:37:55.968786Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"nv       1604\nbkl       160\nmel        83\nbcc        64\nakiec      55\nvasc       23\ndf         14\nName: dx, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"model = torch.load('/kaggle/working/model.pth')\nmodel.eval()  # switch model to the evaluation mode\npreds = torch.zeros((len(test), 7), dtype=torch.float32, device=device)\nwith torch.no_grad():\n\n  for i, x_test in enumerate(test_loader):  \n      x_test = torch.tensor(x_test, device=device, dtype=torch.float32)\n      z_test = model(x_test)\n      val_pred = torch.softmax(z_test, dim=1) # use softmax to convert logits to probabilities\n\n      preds[i*x_test.shape[0]:i*x_test.shape[0] + x_test.shape[0]] += z_test\n\n            \n  gc.collect()   \n           \n","metadata":{"execution":{"iopub.status.busy":"2023-05-14T00:37:55.972044Z","iopub.execute_input":"2023-05-14T00:37:55.972844Z","iopub.status.idle":"2023-05-14T00:39:15.504047Z","shell.execute_reply.started":"2023-05-14T00:37:55.972762Z","shell.execute_reply":"2023-05-14T00:39:15.503134Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score,recall_score, f1_score\n\nfrom sklearn.preprocessing import LabelBinarizer\n\n# Convert the target data to one-hot encoded format\nlb = LabelBinarizer()\ntest_labels = lb.fit_transform(test_df['target'])\n\n# Get predictions for the test set\ntest_preds = preds.cpu()\n\n# Convert the predictions to one-hot encoded format if needed\nif len(test_preds.shape) > 1 and test_preds.shape[1] > 1:\n    test_preds = np.argmax(test_preds, axis=1)\n    test_preds = lb.transform(test_preds)\n\n# Calculate metrics\nacc = accuracy_score(test_labels, test_preds)\nprec = precision_score(test_labels, test_preds, average='macro')\nrec = recall_score(test_labels, test_preds, average='macro')\nf1 = f1_score(test_labels, test_preds, average='macro')\nroc = roc_auc_score(test_labels, test_preds, multi_class='ovr')\n","metadata":{"execution":{"iopub.status.busy":"2023-05-14T00:39:15.509507Z","iopub.execute_input":"2023-05-14T00:39:15.511772Z","iopub.status.idle":"2023-05-14T00:39:15.570015Z","shell.execute_reply.started":"2023-05-14T00:39:15.511727Z","shell.execute_reply":"2023-05-14T00:39:15.569148Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"print(\"acc \", acc)\nprint(\"prec \",prec)\nprint(\"rec \",rec)\nprint(\"f1 \",f1)\nprint(\"roc \",roc)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T00:39:15.574563Z","iopub.execute_input":"2023-05-14T00:39:15.582822Z","iopub.status.idle":"2023-05-14T00:39:15.596940Z","shell.execute_reply.started":"2023-05-14T00:39:15.582781Z","shell.execute_reply":"2023-05-14T00:39:15.596040Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"acc  0.9296055916125812\nprec  0.806160272802299\nrec  0.7553516677933942\nf1  0.7751363911641436\nroc  0.8644692039378539\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Generate the confusion matrix\nconf_matrix = confusion_matrix(test_labels.argmax(axis=1), test_preds.argmax(axis=1))\n\n# Create a heatmap of the confusion matrix\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n\n# Set the axis labels and title\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title('Confusion Matrix')\n\n# Display the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-14T00:39:15.602520Z","iopub.execute_input":"2023-05-14T00:39:15.604707Z","iopub.status.idle":"2023-05-14T00:39:16.157552Z","shell.execute_reply.started":"2023-05-14T00:39:15.604667Z","shell.execute_reply":"2023-05-14T00:39:16.156706Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"# Extract the row and column corresponding to class 4: mel\nclass_idx = 4\nfn = conf_matrix[class_idx, :].sum() - conf_matrix[class_idx, class_idx]\n\n# Calculate the percentage of instances from class 4 that were classified as another class\nfn_percent = (fn / conf_matrix[class_idx, :].sum()) * 100\n\n# Print the results\nprint(f\"False Negative Rate for mel: {fn_percent:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2023-05-14T00:39:16.161598Z","iopub.execute_input":"2023-05-14T00:39:16.163722Z","iopub.status.idle":"2023-05-14T00:39:16.174702Z","shell.execute_reply.started":"2023-05-14T00:39:16.163680Z","shell.execute_reply":"2023-05-14T00:39:16.173826Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"False Negative Rate for mel: 45.78%\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}