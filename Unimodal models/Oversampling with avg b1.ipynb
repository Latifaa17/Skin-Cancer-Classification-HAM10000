{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### Versions:\n* v9: ColorJitter transformation added\n* v10: Changed the dataset to [this one](https://www.kaggle.com/shonenkov/melanoma-merged-external-data-512x512-jpeg) with external data.\n* v11: Switched to [another dataset](https://www.kaggle.com/nroman/melanoma-external-malignant-256/) which I've created by myself. Also switched from StratifiedKFold to GroupKFold\n* v12: Switched to efficientnet-b1","metadata":{}},{"cell_type":"code","source":"!pip install efficientnet_pytorch torchtoolbox","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-05-16T21:10:37.986236Z","iopub.execute_input":"2023-05-16T21:10:37.986556Z","iopub.status.idle":"2023-05-16T21:10:48.882688Z","shell.execute_reply.started":"2023-05-16T21:10:37.986517Z","shell.execute_reply":"2023-05-16T21:10:48.881692Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting efficientnet_pytorch\n  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\nCollecting torchtoolbox\n  Downloading torchtoolbox-0.1.8.2-py3-none-any.whl (84 kB)\n\u001b[K     |████████████████████████████████| 84 kB 2.8 MB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet_pytorch) (1.5.0)\nRequirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (4.2.0.34)\nRequirement already satisfied: prettytable in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (0.7.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (4.45.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (0.22.2.post1)\nRequirement already satisfied: pyarrow in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (0.16.0)\nRequirement already satisfied: tensorboard in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (2.1.1)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (5.3.1)\nCollecting lmdb\n  Downloading lmdb-1.4.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (294 kB)\n\u001b[K     |████████████████████████████████| 294 kB 42.0 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (2.9.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (1.18.1)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (1.4.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (1.14.0)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet_pytorch) (0.18.2)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->torchtoolbox) (0.14.1)\nRequirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (3.11.4)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (0.4.1)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (3.2.1)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (0.9.0)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (1.0.1)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (1.14.0)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (46.1.3.post20200325)\nRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (0.34.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (2.23.0)\nRequirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (1.28.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers->torchtoolbox) (2020.4.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers->torchtoolbox) (3.0.10)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from transformers->torchtoolbox) (0.1.86)\nRequirement already satisfied: tokenizers==0.7.0 in /opt/conda/lib/python3.7/site-packages (from transformers->torchtoolbox) (0.7.0)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers->torchtoolbox) (0.0.43)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->torchtoolbox) (1.2.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->torchtoolbox) (0.2.7)\nRequirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->torchtoolbox) (4.0)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->torchtoolbox) (3.1.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->torchtoolbox) (2020.4.5.1)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->torchtoolbox) (1.24.3)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->torchtoolbox) (3.0.4)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->torchtoolbox) (2.9)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers->torchtoolbox) (7.1.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->torchtoolbox) (3.0.1)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->torchtoolbox) (0.4.8)\nBuilding wheels for collected packages: efficientnet-pytorch\n  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=75023d08d2be4a6033bc2e4da59e8b7852e47ed5145c693e5d2d63114771c8fe\n  Stored in directory: /root/.cache/pip/wheels/0e/cc/b2/49e74588263573ff778da58cc99b9c6349b496636a7e165be6\nSuccessfully built efficientnet-pytorch\nInstalling collected packages: efficientnet-pytorch, lmdb, torchtoolbox\nSuccessfully installed efficientnet-pytorch-0.7.1 lmdb-1.4.1 torchtoolbox-0.1.8.2\n\u001b[33mWARNING: You are using pip version 20.1; however, version 23.1.2 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torchvision\nfrom torchvision import models,transforms\n\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold\nimport pandas as pd\nimport numpy as np\nimport gc\nimport os\nimport cv2\nimport time\nimport datetime\nimport warnings\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom efficientnet_pytorch import EfficientNet\n\nfrom sklearn.model_selection import train_test_split\n\nimport torch.nn.functional as F\n\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-16T21:11:50.216949Z","iopub.execute_input":"2023-05-16T21:11:50.217355Z","iopub.status.idle":"2023-05-16T21:11:50.232731Z","shell.execute_reply.started":"2023-05-16T21:11:50.217322Z","shell.execute_reply":"2023-05-16T21:11:50.231598Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# At least fixing some random seeds. \n# It is still impossible to make results 100% reproducible when using GPU\nwarnings.simplefilter('ignore')\ntorch.manual_seed(47)\nnp.random.seed(47)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T21:11:46.554911Z","iopub.execute_input":"2023-05-16T21:11:46.555305Z","iopub.status.idle":"2023-05-16T21:11:46.563081Z","shell.execute_reply.started":"2023-05-16T21:11:46.555272Z","shell.execute_reply":"2023-05-16T21:11:46.562280Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-05-16T21:11:47.533430Z","iopub.execute_input":"2023-05-16T21:11:47.533784Z","iopub.status.idle":"2023-05-16T21:11:47.560730Z","shell.execute_reply.started":"2023-05-16T21:11:47.533744Z","shell.execute_reply":"2023-05-16T21:11:47.559131Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class MelanomaDataset(Dataset):\n    def __init__(self, df: pd.DataFrame, train: bool = True, transforms = None):\n        \"\"\"\n        Class initialization\n        Args:\n            df (pd.DataFrame): DataFrame with data description\n            imfolder (str): folder with images\n            train (bool): flag of whether a training dataset is being initialized or testing one\n            transforms: image transformation method to be applied\n            \n        \"\"\"\n        self.df = df\n        self.path1 = '/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1'\n        self.path2 = '/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2'\n        self.transforms = transforms\n        self.train = train\n        \n    def __getitem__(self, index):\n        \n        image_path = os.path.join(self.path1, self.df.iloc[index]['image_id'] + '.jpg')\n        if os.path.exists(image_path):\n            image = cv2.imread(image_path)\n        else:\n            # If the image is not in part 1, try to load it from part 2\n            image_path = os.path.join(self.path2, self.df.iloc[index]['image_id'] + '.jpg')\n            if os.path.exists(image_path):\n                image = cv2.imread(image_path)\n\n        if self.transforms:\n            x = self.transforms(image)\n            \n        if self.train:\n            y = self.df.loc[index]['target']\n            return x, y\n        else:\n            return x\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def _get_label(self, dataset, idx):\n        return self.df.iloc[idx]['target']\n    \n    \n","metadata":{"execution":{"iopub.status.busy":"2023-05-16T21:11:53.006858Z","iopub.execute_input":"2023-05-16T21:11:53.007240Z","iopub.status.idle":"2023-05-16T21:11:53.022132Z","shell.execute_reply.started":"2023-05-16T21:11:53.007205Z","shell.execute_reply":"2023-05-16T21:11:53.021164Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.ToPILImage(),\n    #transforms.RandomResizedCrop(size=240, scale=(0.8, 1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n])\ntest_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n])\n","metadata":{"execution":{"iopub.status.busy":"2023-05-16T21:11:53.661172Z","iopub.execute_input":"2023-05-16T21:11:53.661530Z","iopub.status.idle":"2023-05-16T21:11:53.668987Z","shell.execute_reply.started":"2023-05-16T21:11:53.661497Z","shell.execute_reply":"2023-05-16T21:11:53.667981Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv')\n\n\n# this will tell us how many images are associated with each lesion_id\ndf_undup = df.groupby('lesion_id').count()\n# now we filter out lesion_id's that have only one image associated with it\ndf_undup = df_undup[df_undup['image_id'] == 1]\ndf_undup.reset_index(inplace=True)\n\ndef get_duplicates(x):\n    unique_list = list(df_undup['lesion_id'])\n    if x in unique_list:\n        return 'unduplicated'\n    else:\n        return 'duplicated'\n\n# create a new colum that is a copy of the lesion_id column\ndf['duplicates'] = df['lesion_id']\n# apply the function to this new column\ndf['duplicates'] = df['duplicates'].apply(get_duplicates)\n\ndf_undup  = df[df['duplicates'] == 'unduplicated']\n\n#now we create a test set using df_undup because we are sure that none of these images have augmented duplicates in the train set\ny = df_undup['dx']\n_, test_df_csv = train_test_split(df_undup, test_size=0.7265, random_state=101, stratify=y)\ntest_df_csv.shape\n\n# This set will be df_original excluding all rows that are in the test set\n# This function identifies if an image is part of the train or test set.\ndef get_test_rows(x):\n    # create a list of all the lesion_id's in the val test\n    test_list = list(test_df_csv['image_id'])\n    if str(x) in test_list:\n        return 'test'\n    else:\n        return 'train'\n\n# identify train and test rows\n# create a new colum that is a copy of the image_id column\ndf['train_or_test'] = df['image_id']\n# apply the function to this new column\ndf['train_or_test'] = df['train_or_test'].apply(get_test_rows)\n# filter out train rows\ntrain_df_csv = df[df['train_or_test'] == 'train']\n\n# Split the test into 50% test and 50% validation\ntest_df, val_df = train_test_split(test_df_csv, test_size=0.5, random_state=101, stratify=test_df_csv['dx'])\n\ntrain_df = train_df_csv\nprint(len(train_df))\nprint(len(val_df))\nprint(len(test_df))","metadata":{"execution":{"iopub.status.busy":"2023-05-16T21:11:54.097738Z","iopub.execute_input":"2023-05-16T21:11:54.098190Z","iopub.status.idle":"2023-05-16T21:12:07.582822Z","shell.execute_reply.started":"2023-05-16T21:11:54.098150Z","shell.execute_reply":"2023-05-16T21:12:07.581793Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"6009\n2003\n2003\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df.dx.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-05-16T21:12:07.584817Z","iopub.execute_input":"2023-05-16T21:12:07.585136Z","iopub.status.idle":"2023-05-16T21:12:07.596731Z","shell.execute_reply.started":"2023-05-16T21:12:07.585104Z","shell.execute_reply":"2023-05-16T21:12:07.595700Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"nv       3497\nmel       946\nbkl       779\nbcc       387\nakiec     217\nvasc       96\ndf         87\nName: dx, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ntrain_df['target'] = le.fit_transform(train_df['dx'])\nval_df['target'] = le.fit_transform(val_df['dx'])\ntest_df['target'] = le.fit_transform(test_df['dx'])","metadata":{"execution":{"iopub.status.busy":"2023-05-16T21:12:07.598238Z","iopub.execute_input":"2023-05-16T21:12:07.598825Z","iopub.status.idle":"2023-05-16T21:12:07.614095Z","shell.execute_reply.started":"2023-05-16T21:12:07.598780Z","shell.execute_reply":"2023-05-16T21:12:07.613314Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_df.target.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-05-16T21:12:07.615809Z","iopub.execute_input":"2023-05-16T21:12:07.616287Z","iopub.status.idle":"2023-05-16T21:12:07.633567Z","shell.execute_reply.started":"2023-05-16T21:12:07.616241Z","shell.execute_reply":"2023-05-16T21:12:07.632708Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"5    3497\n4     946\n2     779\n1     387\n0     217\n6      96\n3      87\nName: target, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"from collections import Counter\nfrom sklearn.utils import resample\n\n# Count the number of samples for each class\nclass_counts = Counter(train_df['target'])\n\n# Get the size of the majority class\nmajority_class_size = max(class_counts.values())\n\n# Oversample minority classes to match the size of the majority class\nfor class_label, class_size in class_counts.items():\n    if class_label != train_df['target'].mode()[0]:\n        # Determine the number of times to resample the class\n        resample_rate = int(majority_class_size / class_size)\n        \n        X_subset = train_df[train_df['target'] == class_label].drop(['target'], axis=1)\n        y_subset = train_df[train_df['target'] == class_label]['target']\n        \n        # Resample the class with replacement\n        X_subset_resampled, y_subset_resampled = resample(X_subset, y_subset, \n                                                          replace=True, n_samples=(resample_rate-1)*class_size, \n                                                          random_state=42)\n        \n        # Concatenate the resampled data with the original data\n        train_df = pd.concat([train_df, pd.concat([X_subset_resampled, y_subset_resampled], axis=1)])\n\n# Verify that all classes have the same number of samples\nprint(train_df['target'].value_counts())\n","metadata":{"execution":{"iopub.status.busy":"2023-05-16T21:12:07.636915Z","iopub.execute_input":"2023-05-16T21:12:07.637360Z","iopub.status.idle":"2023-05-16T21:12:07.728212Z","shell.execute_reply.started":"2023-05-16T21:12:07.637305Z","shell.execute_reply":"2023-05-16T21:12:07.727295Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"5    3497\n1    3483\n3    3480\n0    3472\n6    3456\n2    3116\n4    2838\nName: target, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df['sex'] = train_df['sex'].map({'male': 1, 'female': 0})\nval_df['sex'] = val_df['sex'].map({'male': 1, 'female': 0})\ntest_df['sex'] = test_df['sex'].map({'male': 1, 'female': 0})\n\ntrain_df['sex'] = train_df['sex'].fillna(-1)\nval_df['sex'] = val_df['sex'].fillna(-1)\ntest_df['sex'] = test_df['sex'].fillna(-1)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-16T21:12:07.731382Z","iopub.execute_input":"2023-05-16T21:12:07.731656Z","iopub.status.idle":"2023-05-16T21:12:07.750181Z","shell.execute_reply.started":"2023-05-16T21:12:07.731628Z","shell.execute_reply":"2023-05-16T21:12:07.749473Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_df = pd.get_dummies(train_df, columns=['localization'],prefix='site')\nval_df = pd.get_dummies(val_df, columns=['localization'],prefix='site')\n\ntest_df = pd.get_dummies(test_df, columns=['localization'],prefix='site')\n\n# adding missing cols to val and test sets\nval_df = val_df.reindex(columns=train_df.columns, fill_value=0)\ntest_df = test_df.reindex(columns=train_df.columns, fill_value=0)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T21:12:07.752843Z","iopub.execute_input":"2023-05-16T21:12:07.753228Z","iopub.status.idle":"2023-05-16T21:12:07.784904Z","shell.execute_reply.started":"2023-05-16T21:12:07.753198Z","shell.execute_reply":"2023-05-16T21:12:07.784208Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"test = MelanomaDataset(df=test_df,\n                       train=False,\n                       transforms=test_transform)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T21:12:07.786296Z","iopub.execute_input":"2023-05-16T21:12:07.786839Z","iopub.status.idle":"2023-05-16T21:12:07.791687Z","shell.execute_reply.started":"2023-05-16T21:12:07.786796Z","shell.execute_reply":"2023-05-16T21:12:07.790573Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"    \nclass Net(nn.Module):\n    def __init__(self,b1 = False, b4 = False):\n        super(Net, self).__init__()\n        self.b1 = b1\n        self.b4 = b4\n        if self.b1:\n            self.arch = EfficientNet.from_pretrained('efficientnet-b1')\n            self.arch._fc = nn.Linear(in_features=1280, out_features=7, bias=True)\n            \n        elif self.b4:\n            self.arch = EfficientNet.from_pretrained('efficientnet-b4')\n            self.arch._fc = nn.Linear(in_features=1792, out_features=7, bias=True)\n\n        \n    def forward(self, x):\n        x = self.arch(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-05-16T21:12:07.793045Z","iopub.execute_input":"2023-05-16T21:12:07.793609Z","iopub.status.idle":"2023-05-16T21:12:07.803909Z","shell.execute_reply.started":"2023-05-16T21:12:07.793571Z","shell.execute_reply":"2023-05-16T21:12:07.803105Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self,b1 = False, b4 = False):\n        super(Net, self).__init__()\n        self.b1 = b1\n        self.b4 = b4\n        \n        if self.b1:\n            self.features = EfficientNet.from_pretrained('efficientnet-b1')\n            self.classification = nn.Sequential(nn.Linear(1280, 7))  \n        elif self.b4:\n            self.features = EfficientNet.from_pretrained('efficientnet-b4')\n            self.classification = nn.Sequential(nn.Linear(1792, 7))  \n\n        \n    def forward(self, x):\n        x = self.features.extract_features(x)\n        \n        if self.b1:\n            x = F.avg_pool2d(x, x.size()[2:]).reshape(-1, 1280)\n        elif self.b4:\n            x = F.avg_pool2d(x, x.size()[2:]).reshape(-1, 1792)       \n        \n        out = self.classification(x)\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-05-16T21:12:07.805103Z","iopub.execute_input":"2023-05-16T21:12:07.805667Z","iopub.status.idle":"2023-05-16T21:12:07.818096Z","shell.execute_reply.started":"2023-05-16T21:12:07.805628Z","shell.execute_reply":"2023-05-16T21:12:07.817365Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"epochs = 3  # Number of epochs to run\nmodel_path = 'model.pth'  # Path and filename to save model to\nes_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\nTTA = 3 # Test Time Augmentation \n\noof = np.zeros((len(train_df), 7))  # Out Of Fold predictions\n","metadata":{"execution":{"iopub.status.busy":"2023-05-16T21:12:07.819316Z","iopub.execute_input":"2023-05-16T21:12:07.819867Z","iopub.status.idle":"2023-05-16T21:12:07.828874Z","shell.execute_reply.started":"2023-05-16T21:12:07.819828Z","shell.execute_reply":"2023-05-16T21:12:07.828097Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nimport tqdm.notebook as tq\nimport torch.nn.functional as F\nfrom sklearn.utils.class_weight import compute_class_weight","metadata":{"execution":{"iopub.status.busy":"2023-05-16T21:12:07.830404Z","iopub.execute_input":"2023-05-16T21:12:07.830840Z","iopub.status.idle":"2023-05-16T21:12:07.842123Z","shell.execute_reply.started":"2023-05-16T21:12:07.830800Z","shell.execute_reply":"2023-05-16T21:12:07.841197Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Define Focal loss implementation\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=2, alpha=None, reduction='mean'):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n        self.reduction = reduction\n\n    def forward(self, inputs, targets):\n        CE_loss = F.cross_entropy(inputs, targets, reduction=self.reduction, weight=self.alpha)\n        pt = torch.exp(-CE_loss)\n        F_loss = ((1-pt)**self.gamma) * CE_loss\n        if self.reduction == 'mean': return F_loss.mean()\n        else: return F_loss.sum()","metadata":{"execution":{"iopub.status.busy":"2023-05-16T21:12:07.843518Z","iopub.execute_input":"2023-05-16T21:12:07.843917Z","iopub.status.idle":"2023-05-16T21:12:07.856629Z","shell.execute_reply.started":"2023-05-16T21:12:07.843880Z","shell.execute_reply":"2023-05-16T21:12:07.855873Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"\nbest_val = None  # Best validation score within this fold\npatience = es_patience  # Current patience counter\n#     arch = EfficientNet.from_pretrained('efficientnet-b1')\n#     arch = models.resnet50(pretrained=True)\n\n\nmodel = Net(b1=True)  # New model for each fold\nmodel = model.to(device)\n\n#giving more importance to mel\n\n# Define weight factors\nclass_factor_interest = 2.0\nclass_factor_minority = 1.0\nclass_factor_majority = 0.5\n\n# Get class labels and weights\nclass_labels = np.unique(train_df['target'])\nclass_weights_all = compute_class_weight('balanced', classes=class_labels, y=train_df['target'])\n\n# Modify class weights to reflect weight factors\nclass_weights = np.zeros_like(class_weights_all)\nfor i, weight in enumerate(class_weights_all):\n    if class_labels[i] == 4:  # class of interest\n        class_weights[i] = weight * class_factor_interest\n    elif weight == np.max(class_weights_all):  # majority class\n        class_weights[i] = weight * class_factor_majority\n    else:  # minority class\n        class_weights[i] = weight * class_factor_minority\n\n# Convert class weights to PyTorch tensor\nclass_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n\n# Initialize Focal loss object\nfocal_loss = FocalLoss(gamma=2, alpha=class_weights)\n\n\noptim = torch.optim.Adam(model.parameters(), lr=0.0001)\nscheduler = ReduceLROnPlateau(optimizer=optim, mode='max', patience=1, verbose=True, factor=0.4)\ncriterion = nn.CrossEntropyLoss(weight=class_weights)\n\ntrain = MelanomaDataset(df=train_df.reset_index(drop=True), \n                        train=True, \n                        transforms=train_transform)\nval = MelanomaDataset(df=val_df.reset_index(drop=True), \n                        train=True, \n                        transforms=test_transform)\n\ntrain_loader = DataLoader(dataset=train, batch_size=16, shuffle=True, num_workers=0)\nval_loader = DataLoader(dataset=val, batch_size=8, shuffle=False, num_workers=0)\ntest_loader = DataLoader(dataset=test, batch_size=8, shuffle=False, num_workers=0)\n\nfor epoch in tqdm(range(epochs)):\n    start_time = time.time()\n    correct = 0\n    epoch_loss = 0\n    model.train()\n\n    for x, y in tq.tqdm(train_loader):\n        x = torch.tensor(x, device=device, dtype=torch.float32)\n        y = torch.tensor(y, device=device, dtype=torch.long)\n        optim.zero_grad()\n        z = model(x)\n#         loss =  focal_loss(z, y)\n        loss =  criterion(z, y)\n        loss.backward()\n        optim.step()\n        pred = torch.argmax(z, dim=1)  # get the index of the highest value in out\n        correct += (pred.cpu() == y.cpu()).sum().item()  # tracking number of correctly predicted samples\n        epoch_loss += loss.item()\n    train_acc = correct / len(train_df)\n\n    model.eval()  # switch model to the evaluation mode\n    val_preds = torch.zeros((len(val_df), 7), dtype=torch.float32, device=device)\n    with torch.no_grad():  # Do not calculate gradient since we are only predicting\n        # Predicting on validation set\n        for j, (x_val, y_val) in enumerate(val_loader):\n            x_val = torch.tensor(x_val, device=device, dtype=torch.float32)\n            y_val = torch.tensor(y_val, device=device, dtype=torch.long)\n            z_val = model(x_val)\n            val_pred = torch.softmax(z_val, dim=1) # use softmax to convert logits to probabilities\n            val_preds[j*x_val.shape[0]:j*x_val.shape[0] + x_val.shape[0]] = val_pred\n\n        val_preds = torch.softmax(val_preds, dim=1) # use softmax to convert logits to probabilities\n        val_acc = accuracy_score(val_df['target'].values, torch.argmax(val_preds.cpu(), dim=1))\n        val_preds = val_preds.cpu().detach().numpy()\n        val_preds = val_preds.reshape(-1, 7) # reshape val_preds to a 2D tensor\n\n        val_roc = roc_auc_score(val_df['target'].values, val_preds, multi_class='ovr')\n\n\n        print('Epoch {:03}: | Loss: {:.3f} | Train acc: {:.3f} | Val acc: {:.3f} | Val roc_auc: {:.3f} | Training time: {}'.format(\n        epoch + 1, \n        epoch_loss/len(train_loader), \n        train_acc, \n        val_acc, \n        val_roc, \n        str(datetime.timedelta(seconds=time.time() - start_time))[:7]))\n\n        scheduler.step(val_roc)\n        # During the first iteration (first epoch) best validation is set to None\n        if not best_val:\n            best_val = val_roc  # So any validation roc_auc we have is the best one for now\n            torch.save(model, model_path)  # Saving the model\n            continue\n\n        if val_roc >= best_val:\n            best_val = val_roc\n            patience = es_patience  # Resetting patience since we have new best validation accuracy\n            torch.save(model, model_path)  # Saving current best model\n        else:\n            patience -= 1\n            if patience == 0:\n                print('Early stopping. Best Val roc_auc: {:.3f}'.format(best_val))\n                break\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-16T21:12:15.462380Z","iopub.execute_input":"2023-05-16T21:12:15.462731Z","iopub.status.idle":"2023-05-16T22:13:05.553509Z","shell.execute_reply.started":"2023-05-16T21:12:15.462698Z","shell.execute_reply":"2023-05-16T22:13:05.552568Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b1-f1951068.pth\" to /root/.cache/torch/checkpoints/efficientnet-b1-f1951068.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=31519111.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85ca2cce6ad2414dacd12e60ab0eb409"}},"metadata":{}},{"name":"stdout","text":"\nLoaded pretrained weights for efficientnet-b1\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/3 [00:00<?, ?it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=1459.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7fce3678b6b48d49514cd7f7566c656"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 1/3 [21:22<42:44, 1282.41s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 001: | Loss: 0.546 | Train acc: 0.810 | Val acc: 0.901 | Val roc_auc: 0.961 | Training time: 0:21:22\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=1459.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c693e652dbee46a98f99acce1ef26e35"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 2/3 [41:04<20:52, 1252.30s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 002: | Loss: 0.191 | Train acc: 0.939 | Val acc: 0.925 | Val roc_auc: 0.976 | Training time: 0:19:41\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=1459.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44eb95d6c9684b09a283597c079fbe66"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3/3 [1:00:45<00:00, 1215.10s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 003: | Loss: 0.118 | Train acc: 0.961 | Val acc: 0.913 | Val roc_auc: 0.974 | Training time: 0:19:40\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"test_loader = DataLoader(dataset=test, batch_size=8, shuffle=False,num_workers=0)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T22:13:05.555616Z","iopub.execute_input":"2023-05-16T22:13:05.556239Z","iopub.status.idle":"2023-05-16T22:13:05.561739Z","shell.execute_reply.started":"2023-05-16T22:13:05.556195Z","shell.execute_reply":"2023-05-16T22:13:05.560788Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"test_df.dx.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-05-16T22:13:05.563126Z","iopub.execute_input":"2023-05-16T22:13:05.563492Z","iopub.status.idle":"2023-05-16T22:13:05.581071Z","shell.execute_reply.started":"2023-05-16T22:13:05.563454Z","shell.execute_reply":"2023-05-16T22:13:05.580339Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"nv       1604\nbkl       160\nmel        83\nbcc        64\nakiec      55\nvasc       23\ndf         14\nName: dx, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"model = torch.load('/kaggle/working/model.pth')\nmodel.eval()  # switch model to the evaluation mode\npreds = torch.zeros((len(test), 7), dtype=torch.float32, device=device)\nwith torch.no_grad():\n\n  for i, x_test in enumerate(test_loader):  \n      x_test = torch.tensor(x_test, device=device, dtype=torch.float32)\n      z_test = model(x_test)\n      val_pred = torch.softmax(z_test, dim=1) # use softmax to convert logits to probabilities\n\n      preds[i*x_test.shape[0]:i*x_test.shape[0] + x_test.shape[0]] += z_test\n\n            \n  gc.collect()   \n           \n","metadata":{"execution":{"iopub.status.busy":"2023-05-16T22:13:05.582527Z","iopub.execute_input":"2023-05-16T22:13:05.584411Z","iopub.status.idle":"2023-05-16T22:14:22.282956Z","shell.execute_reply.started":"2023-05-16T22:13:05.584367Z","shell.execute_reply":"2023-05-16T22:14:22.282117Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score,recall_score, f1_score\n\nfrom sklearn.preprocessing import LabelBinarizer\n\n# Convert the target data to one-hot encoded format\nlb = LabelBinarizer()\ntest_labels = lb.fit_transform(test_df['target'])\n\n# Get predictions for the test set\ntest_preds = preds.cpu()\n\n# Convert the predictions to one-hot encoded format if needed\nif len(test_preds.shape) > 1 and test_preds.shape[1] > 1:\n    test_preds = np.argmax(test_preds, axis=1)\n    test_preds = lb.transform(test_preds)\n\n# Calculate metrics\nacc = accuracy_score(test_labels, test_preds)\nprec = precision_score(test_labels, test_preds, average='macro')\nrec = recall_score(test_labels, test_preds, average='macro')\nf1 = f1_score(test_labels, test_preds, average='macro')\nroc = roc_auc_score(test_labels, test_preds, multi_class='ovr')\n","metadata":{"execution":{"iopub.status.busy":"2023-05-16T22:14:22.285113Z","iopub.execute_input":"2023-05-16T22:14:22.285384Z","iopub.status.idle":"2023-05-16T22:14:22.323314Z","shell.execute_reply.started":"2023-05-16T22:14:22.285358Z","shell.execute_reply":"2023-05-16T22:14:22.322615Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"print(\"acc \", acc)\nprint(\"prec \",prec)\nprint(\"rec \",rec)\nprint(\"f1 \",f1)\nprint(\"roc \",roc)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T22:14:22.325095Z","iopub.execute_input":"2023-05-16T22:14:22.325470Z","iopub.status.idle":"2023-05-16T22:14:22.333762Z","shell.execute_reply.started":"2023-05-16T22:14:22.325431Z","shell.execute_reply":"2023-05-16T22:14:22.332881Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"acc  0.9380928607089366\nprec  0.844069482784475\nrec  0.7934399888258348\nf1  0.8094021025574071\nroc  0.8879451674154241\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Generate the confusion matrix\nconf_matrix = confusion_matrix(test_labels.argmax(axis=1), test_preds.argmax(axis=1))\n\n# Create a heatmap of the confusion matrix\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n\n# Set the axis labels and title\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title('Confusion Matrix')\n\n# Display the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-16T22:14:22.335192Z","iopub.execute_input":"2023-05-16T22:14:22.335733Z","iopub.status.idle":"2023-05-16T22:14:22.723931Z","shell.execute_reply.started":"2023-05-16T22:14:22.335694Z","shell.execute_reply":"2023-05-16T22:14:22.723019Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 2 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAXUAAAEWCAYAAACZnQc8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de5xN9frA8c9jhoioiRm3qUw4hXROLt0lRULGJdLpoqvquBQpVEenzlF0Op1zOqVyqYRIRYSUH8agG0lUuqjExMwoUS6NmT3P74+1ZtqNueyZ2Xuv1fa8vdbL3uv2ffbae5793d/1Xd8lqooxxpjYUMXrAIwxxoSPJXVjjIkhltSNMSaGWFI3xpgYYkndGGNiiCV1Y4yJIZbUTaWJSA0ReV1E9orIy5XYz1Ui8lY4Y/OCiLwhIgO9jsMcmSypH0FE5M8isk5E9onITjf5nBeGXV8OJAHHq2q/iu5EVWeqapcwxPMbItJRRFRE5haZf7o7Py3E/fxNRGaUtZ6qXqqq0yoYrjGVYkn9CCEiI4D/AA/hJOATgIlAahh2fyLwharmhWFfkbILOEdEjg+aNxD4IlwFiMP+poyn7AN4BBCROsCDwGBVnauq+1U1V1VfV9W73HWOEpH/iMgOd/qPiBzlLusoIhkicqeIZLu1/OvdZQ8AY4Er3F8ANxat0YrISW6NON59fp2IfC0iP4vINyJyVdD81UHbnSMia91mnbUick7QsjQR+buIrHH385aI1C3lMBwCXgMGuNvHAf2BmUWO1X9FZLuI/CQiH4jI+e78rsA9Qa/zo6A4xonIGuAAkOLOu8ld/pSIvBK0/wkiskxEJOQ30JhysKR+ZDgbqA7MK2Wde4GzgD8CpwPtgfuCltcH6gCNgBuBJ0XkOFW9H6f2/5Kq1lLVqaUFIiI1gceBS1X1GOAcYEMx6yUAi9x1jwceAxYVqWn/GbgeSASqASNLKxt4AbjWfXwJ8Amwo8g6a3GOQQLwIvCyiFRX1SVFXufpQdtcAwwCjgG+LbK/O4HW7hfW+TjHbqDa+BwmQiypHxmOB74vo3nkKuBBVc1W1V3AAzjJqkCuuzxXVRcD+4A/VDCefKCViNRQ1Z2q+kkx63QHvlTV6aqap6qzgM+Ay4LWeU5Vv1DVg8AcnGRcIlV9G0gQkT/gJPcXillnhqr+4Jb5L+Aoyn6dz6vqJ+42uUX2dwC4GudLaQYwVFUzytifMRVmSf3I8ANQt6D5owQN+W0t81t3XuE+inwpHABqlTcQVd0PXAHcCuwUkUUickoI8RTE1CjoeWYF4pkODAEupJhfLm4T02a3yWcPzq+T0pp1ALaXtlBV3we+BgTny8eYiLGkfmR4B/gF6FXKOjtwTngWOIHDmyZCtR84Ouh5/eCFqvqmqnYGGuDUvieHEE9BTN9VMKYC04G/AIvdWnQht3lkFE5b+3GqeiywFycZA5TUZFJqU4qIDMap8e8A7q546MaUzZL6EUBV9+KczHxSRHqJyNEiUlVELhWRR9zVZgH3iUg994TjWJzmgorYAHQQkRPck7RjChaISJKI9HTb1nNwmnECxexjMdDc7YYZLyJXAC2AhRWMCQBV/Qa4AOccQlHHAHk4PWXiRWQsUDtoeRZwUnl6uIhIc+AfOE0w1wB3i0ipzUTGVIYl9SOEqj4GjMA5+bkLp8lgCE6PEHASzzpgI7AJWO/Oq0hZS4GX3H19wG8TcRWck4c7gN04CfYvxezjB6CHu+4PODXcHqr6fUViKrLv1apa3K+QN4E3cLo5fovz6ya4aaXgwqofRGR9WeW4zV0zgAmq+pGqfonTg2Z6Qc8iY8JN7CS8McbEDqupG2NMDLGkbowxMcSSujHGxBBL6sYYE0NKuxjFUz/n5PvyDG7VOPseNMZvqsdT6bF0avxpSMg55+CHT/h27B7LUMYYE0N8W1M3xpioipFRky2pG2MMQJU4ryMIC0vqxhgDECND3FtSN8YYsOYXY4yJKVZTN8aYGGI1dWOMiSFWUzfGmBhivV+MMSaGWPOLMcbEEGt+8a9AIMA1V/YjMTGR/zzxNHv37mHMXSPYueM7GjRsxPhH/03t2nW8DpNAIMCV/fuSmJTEExOf8ToccnJyuP7aq8g9dIi8QIDOXS7hL0OGeR1WoTWr0pkwfhz5gXx69+3HjTcP8jokXx+zSzt34uiaNYmrUoW4+DhmzZnrdUiAP99HwGrqfjZr5nSaNElh//59ADw/dTLtzzyb6268meenTub5qZMZNnykx1HCzOkvkJJyMvvcOL1WrVo1pjw7jaNr1iQ3N5frrvkz553fgdane39LzUAgwEPjHuSZyc+RlJTEn6+4nI4XduLkpk09jcvPxwxgynPTOO64BK/DKOTX9xGImaQesVchIqeIyCgReVxE/us+PjVS5RXIysxkTfpKevW5vHDeyhXL6dEzFYAePVNJW74s0mGUKSszk1XpafTue3nZK0eJiHB0zZoA5OXlkZeX55ufpB9v2khy8ok0Tk6marVqdO3WnbQV3r+Pfj5mfuTX9xGAuLjQJx+LSFIXkVHAbECA94G17uNZIjI6EmUW+NcjDzNsxEikyq8vbffuH6hbLxGAuvUS+XH37kiGEJJHxj/E8DvvokoVf9UOAoEA/fukcuH553DW2efQuvXpXocEQHZWFvUb1C98npiURFZWlocR/cqvxwyBW2++kQH9+vDKnJe8jgbw9/uISOiTj0Uqo9wItFPV8ao6w53GA+3dZcUSkUEisk5E1j03ZVK5C121cgUJCQmc2qJlxSOPgpVpTpwtWrbyOpTDxMXFMWfufN5avpKPN23kyy+/8DokAJTDh7oWn/xx+fWYTZsxi5demceTT0/mpVkz+WDdWq9D8vX7iFQJffKxSLWp5wMNgW+LzG/gLiuWqk4CJkHFbpLx0YYPSU9bwZrV6RzKOcS+/fv465i7SUg4nu93ZVO3XiLf78rmuARv2xg3fLietLTlrF6VTk5ODvv372PMqJE8POFRT+MKVrt2bdq1P5O3V6+iWbPmXodDUlJ9MndmFj7PzsoiMTHRw4gO57djlpiYBMDxxx9Pp4s78/GmjbRp287TmHz9Pvrly6WSIvWVcwewTETeEJFJ7rQEWAbcHqEyGXL7CBb/XxqvL1nGuEf+Rbv2Z/L3hx/hgo6dWLhgPgALF8znggs7RSqEkNw+/E6WLk/njaXLmfDoY7Q78yxfJPTdu3fz008/AfDLL7/w7jtvc1KTFI+jcrRsdRrbtm0lI2M7uYcOsWTxIs/fR/DvMTtw4EBhR4EDBw7wzttraNq0mcdR+fd9BKymXhpVXSIizXGaWxrhtKdnAGtVNRCJMksz8MabGDNyBPPnvUL9+g0Z/69/RzuE34Xvd2Vz3z2jyc8PkJ+vdLmkKxd0vNDrsACIj49nzL1juW3QTeTnB+jVu68vkpRfj9nuH35g+LDBAOQFAnTr3oNzz+/gcVT+fR+BmKmpi6ovbwVq9yg1xoQsLPcovfTfod+j9I3hpZYnIs8CPYBsVW1VZNlI4J9APVX93p03Bud8YwAYpqpvuvPbAM8DNYDFwO1aRtK2DGWMMRDu5pfnga6HFSGSDHQGtgXNawEMAFq620wUkYJ+k08Bg4Bm7nTYPouypG6MMRDWLo2qmg4U13f638Dd8JtuQKnAbFXNUdVvgC1AexFpANRW1Xfc2vkLQK+yyrakbowxUK6aenD3a3cqc6wDEekJfKeqHxVZ1AjYHvQ8w53XyH1cdH6pYnKYAGOMKbdy9GoJ7n4d0q5FjgbuBboUt7i4IkqZXypL6sYYA5EeT/1koAnwkXuxVWNgvYi0x6mBJwet2xjY4c5vXMz8UlnzizHGQESHCVDVTaqaqKonqepJOAn7DFXNBBYAA0TkKBFpgnNC9H1V3Qn8LCJnifNNcC0wv6yyLKkbYwyEtfeLiMwC3gH+ICIZIlLi8Ciq+gkwB/gUWAIMDrqe5zZgCs7J06+AN8os2/qpl4/1UzfGf8LST73P1ND7qc+90bdXKlmbujHG4KOBxSrJkroxxmBJPeLifTbOeIFDeSUOMumpavH+PF7G/F5IFUvqxhgTM6ymbowxMcSSujHGxBBL6sYYE0tiI6dbUjfGGLCaujHGxJQqPu1xV16W1I0xBqupG2NMbImNnG5J3RhjwGrqxhgTUyypG2NMDImVYQJi43RvKWZOn0bfXj3ok9qdGdOf9zocAoEAV/Xvw/AhtwLwxeefccM1AxjQtyfDh97Gvn37PI7QibF/314M+cstXofyG2tWpdOz+yX06NqZqZNDvpNYxPkxrsydO7nxumvoddml9O7ZnZnTp3kdUiE/Hi9wauqhTn4W00l9y5dfMPfVl5kx62XmvDqfVSvT+PbbrZ7GNHvmdJqkpBQ+/8cDf2Xw7SOY/eoCLux0MdOfn+phdI6Z018gJeVkr8P4jUAgwEPjHmTi01OYt2ARSxYv5KstW7wOy7dxxcXHMfLu0bz2+hvMmPUSs2e96Iu4/Hq8wJL678LXX39F69anU6NGDeLj42nTth3Lly31LJ6srExWr1pJau/LC+dt2/oNZ7RpB0D7s89hhYfxAWRlZrIqPY3efS8ve+Uo+njTRpKTT6RxcjJVq1Wja7fupK1Y5nVYvo2rXr1ETm3REoCaNWuRkpJCdnaWx1H593iBJfUKE5Hro1VW06bN+eCDdezZ8yMHDx5k9ap0sjIzo1X8YR575GGGDR/5m4scUpo2Iz1tOQDL3nqTrMydXoUHwCPjH2L4nXf57kKM7Kws6jeoX/g8MSmJrCzvk5Rf4wr23XcZfLZ5M6e1Pt3rUHx9vCypV9wDJS0QkUEisk5E1k2dUvm2tpSTT+b6G27i1ptvYPCtN9G8+R+Ii4voHcNLtGrlCo5LSCisPRUY+8A4Xp79ItcM6MuBA/upWrWqJ/EBrExbQUJCAi1atvIshpIoh99pzA9/XH6Nq8CB/fu5845h3DX6HmrVquV1OP4+XlKOqaxdiTwrItki8nHQvH+KyGcislFE5onIsUHLxojIFhH5XEQuCZrfRkQ2ucselxAOVkR6v4jIxpIWAUklbaeqk4BJAAdzi3n3K6B333707tsPgMf/8xhJ9UssPqI+2vAhq9JW8PbqdHJyDrF//z7+OuZu/v7wIzzxjNOO/u3Wb1idvtKT+AA2fLietLTlrF6VTk5ODvv372PMqJE8POFRz2IqkJRUn8ydv/7Kys7KIjEx0cOIHH6NCyA3N5cRdwyjW/fLuLhzF6/DAfx9vML86/R54AnghaB5S4ExqponIhOAMcAoEWkBDABaAg2B/xOR5u7Np58CBgHvAouBrpRx8+lI1dSTgGuBy4qZfohQmcXa/YNT3M6dO1i+7C0uvbRHNIsvNOT2ESxamsaCN5bx0IR/0a7dmfz94UcK48vPz+fZyU/Tt98VnsQHcPvwO1m6PJ03li5nwqOP0e7Ms3yR0AFatjqNbdu2kpGxndxDh1iyeBEXXNjJ67B8G5eq8rex95KSksK110WtxbNMfj1eEN7mF1VNB3YXmfeWqua5T98FGruPU4HZqpqjqt8AW4D2ItIAqK2q76iq4nxB9Cqr7Ej1U18I1FLVDUUXiEhahMos1p3Dh7J3zx7i4+MZc+/91K5TJ5rFl+nNJYt4ZfaLAHS8qDOX9erjcUT+5Lx/Y7lt0E3k5wfo1bsvTZs28zos38b14foPWLhgPs2aN6d/n1QAht4xgvM7XOBpXH49XkC0hwm4AXjJfdwIJ8kXyHDn5bqPi84vlThfAP4TruaXcMsN2D1KjfGb6vGVT8knDF0Qcs7Z/kTqLTjNIgUmuc3HhUTkJGChqrYqMv9eoC3QR1VVRJ4E3lHVGe7yqThNLduAh1X1Ynf++cDdqnpZabHZFaXGGEP5TtgGn/8rZxkDgR7ARfprjToDSA5arTGww53fuJj5pbLqnTHGEPkujSLSFRgF9FTVA0GLFgADROQoEWkCNAPeV9WdwM8icpbb6+VaYH5Z5VhN3RhjCO/YLyIyC+gI1BWRDOB+nN4uRwFL3S+Gd1X1VlX9RETmAJ8CecBgt+cLwG04PWlq4PR6KbXnC1iberlZm7ox/hOONvWUEYtDzjlfP9bNJ53rD2c1dWOMwUcXQVWSJXVjjAFiJKdbUjfGGLCaujHGxJQqMXKTDEvqxhiDNb8YY0xMsZp6hPn1W9OvXQd37zvkdQjFSqhVzesQSuTT3ry+5de/yXCJldfn26RujDHRZCdKjTEmhsRITrekbowxEPabZHjGkroxxmA1dWOMiSnWpm6MMTEkRnK6JXVjjAGrqRtjTEyJkZxuSd0YY8CuKDXGmJhizS/GGBNDYiSnHxk3ng4EAvTv24shf7nF61AKrVmVTs/ul9Cja2emTi73TckrZcLf/0rvrhdw/ZW9D1v20oznufDM09i750cA9u7dw/DbbuDSju357z/HRTXOorw8ZiXZ+s3X9O+bWjide+YZzJj+vNdh+TYugLH3jaHj+WfTJ7WH16H8RqRvPB0tR0RSnzn9BVJSTvY6jEKBQICHxj3IxKenMG/BIpYsXshXW7ZErfyuPVKZ8J+nDpufnZXJuvffIal+g8J51apV44ZbhnDbsJFRi684Xh+zkpzUJIU5r85nzqvzmTVnLtWr16DTRZ29Dsu3cQGk9urDU89M8TqMw4iEPpW9L3lWRLJF5OOgeQkislREvnT/Py5o2RgR2SIin4vIJUHz24jIJnfZ4xLCN0rEkrqInCIiF4lIrSLzu0aqzOJkZWayKj2N3n0vj2axpfp400aSk0+kcXIyVatVo2u37qStWBa18k//U1tq165z2Pwn//0ItwwZ8ZtPbY0aR3PaH8+gWjVvR1v0+piF4r1336FxcjINGzbyOpTf8Ftcbdq2o3adwz9/XqtSRUKeQvA8UDTXjQaWqWozYJn7HBFpAQwAWrrbTBSROHebp4BBQDN3KjN/RiSpi8gwYD4wFPhYRFKDFj8UiTJL8sj4hxh+512+GtchOyuL+g3qFz5PTEoiKyvLw4hgTfoK6tZLpGnzP3gaR0n8eMyKevONRVzazV9NCuDfuPwmnM0vqpoO7C4yOxWY5j6eBvQKmj9bVXNU9RtgC9BeRBoAtVX1HVVV4IWgbUoUqUx3M9BGVXsBHYG/isjt7rISj4iIDBKRdSKyLhxtpivTVpCQkECLlq0qva9wUg4fyNvLdrpffjnIjOcnc/0tgz2LoSx+O2ZF5eYeYmXacjp3ieoP0TL5NS4/Kk9SD85V7jQohCKSVHUngPt/oju/EbA9aL0Md14j93HR+aWKVO+XOFXdB6CqW0WkI/CKiJxIKUldVScBkwB+ySvmr7icNny4nrS05axelU5OTg779+9jzKiRPDzh0cruulKSkuqTuTOz8Hl2VhaJiYmlbBFZOzK2k7njO2662mmi2pWdxaBr+/PUc7NIOL6uZ3EF89sxK2r1qnROObUlx9f1x/Eq4Ne4/Kg8dYTgXBWOoosropT5pYpUTT1TRP5YGIWT4HsAdYHTIlTmYW4ffidLl6fzxtLlTHj0MdqdeZbnCR2gZavT2LZtKxkZ28k9dIglixdxwYWdPIsnpWlz5i1ZyezX3mT2a29SLzGJSS/M8U1CB/8ds6KWLF5E127dvQ7jMH6Ny4+i0Psly21Swf0/252fASQHrdcY2OHOb1zM/FJFKqlfC2QGz1DVPFW9FugQoTJ/N+Lj4xlz71huG3QTvXp2o0vXS2natFnUyv/7fXcz+Kar2f7tVvr1uIhFC+aWuv6AXpcw8b//ZMmi+fTrcRFbv/4qSpH+yutjVpqDBw/y7jtvc9HFXbwO5Tf8GteokSO49s8D+HbrN3Tu1IG5r77sdUhAeHu/lGABMNB9PBDnvGPB/AEicpSINME5Ifq+20Tzs4ic5fZ6uTZom5Jfh/r0Ro3haH45ktg9SsvPpx993/LRKYzDVI8vuVk3VBf9752QPxHLhp5dankiMgvnfGJdIAu4H3gNmAOcAGwD+qnqbnf9e4EbgDzgDlV9w53fFqcnTQ3gDWColpG07YpSY4wBqoTxW0tVryxh0UUlrD8OOOzqPlVdB5Srp4cldWOMwd+/RMqjxKQuImeUtqGqrg9/OMYY4w0/dZGtjNJq6v8qZZkC/ul6YIwxlRQjI++WnNRV9cJoBmKMMV6KlfHUy+zSKCJHi8h9IjLJfd5MROyaY2NMTJFy/POzUPqpPwccAs5xn2cA/4hYRMYY44EqEvrkZ6Ek9ZNV9REgF0BVD1LKpf7GGPN7FCvjqYfSpfGQiNTAHXNARE4GciIalTHGRJnPc3XIQknq9wNLgGQRmQmcC1wXyaCMMSbawnnxkZfKTOqqulRE1gNn4TS73K6q30c8MlMufr0c38+X4sfI37AJk1jp/RLqFaUXAOfhNMFUBeZFLCJjjPFArHzJl5nURWQi0BSY5c66RUQuVlX/3lHBGGPK6YhpfsGppbcqGBlMRKYBmyIalTHGRFlspPTQujR+jjNUZIFkYGNkwjHGGG/EfJdGEXkdpw29DrBZRN53n58JvB2d8IwxJjpi5Dxpqc0v3t/3zRhjoiTme7+o6spoBmKMMV7ye7NKqEIZ0OssEVkrIvtE5JCIBETkp2gEZ4wx0RIrY7+E0vvlCWAA8DLQFufmp/64468xxoTJEVNTB1DVLUCcqgZU9TmcG6oaY0zMkHJMZe5LZLiIfCIiH4vILBGpLiIJIrJURL50/z8uaP0xIrJFRD4XkUsq8zpCSeoHRKQasEFEHhGR4UDNyhRqjDF+E1dFQp5KIyKNgGFAW1VtBcThtHaMBpapajNgmfscEWnhLm8JdAUmikhcRV9HKEn9Gne9IcB+nH7qfSpaYDSNvW8MHc8/mz6p/runhx9jy8nJ4c9XXE6/3j3p3bM7E5943OuQfmP6C8/TJ7U7fXv1YPRdI8jJ8cdgoWtWpdOz+yX06NqZqZMneR1OIT9+xsC/xyvM/dTjgRoiEg8cDewAUoFp7vJpQC/3cSowW1VzVPUbYAvQvqKvo8ykrqrfquovqvqTqj6gqiOAhypaYDSl9urDU89M8TqMYvkxtmrVqjHl2Wm8PG8Bc159jTWrV7Hxow1ehwVAVlYWs2a+wIsvvcqrry0kkB9gyRuLvA6LQCDAQ+MeZOLTU5i3YBFLFi/kqy1bvA4L8OdnzM/HS6Q8kwwSkXVB06CC/ajqdzhdwrcBO4G9qvoWkKSqO911dgKJ7iaNgO1BoWS48yokpDb1Ypxd1goi0l5E2rmPW4jICBHpVsHyKqRN23bUrlMnmkWGzI+xiQhH13Ra1vLy8sjLy/PVKEeBvAA5Ob+Ql5fHLwd/oV69xLI3irCPN20kOflEGicnU7VaNbp2607aimVehwX48zPm5+NVRSTkSVUnqWrboKnwJ4fbVp4KNAEaAjVF5OpSii7uj6zC45uGOkpjuYjI/cClQLyILMW5CjUNGC0if1LVcZEo11ReIBDgyn592LZtG1dc+Wdatz7d65AASEpK4trrbqDrxRdSvfpRnHXOuZxz7nleh0V2Vhb1G9QvfJ6YlMSmjTaKRkn8fLzCWH+5GPhGVXc5+5W5OLcDzRKRBqq6U0QaANnu+hk4zdoFGuM011RIiTV1ETmjhKkNzvC7pbkc52YaHYDBQC9VfRC4BLiilDILf9L4qa3tSBIXF8ecufN5a/lKPt60kS+//MLrkAD4ae9e0lYsY9Gby3hr+SoOHjzIotfnex0WWkyFKla6xkWCn49XGNvUtwFnicjR4qx8EbAZWAAMdNcZCBR8gBcAA0TkKBFpgtNl/P2Kvo7Saur/KmXZZ2XsN09VAzg9Z75S1Z/Aub+piOSXtJH7E2YSwC95Ff/5YSqvdu3atGt/Jm+vXkWzZs29Dod3332bRo0ak5CQAMBFF3Vhw4YP6X5ZqqdxJSXVJ3NnZuHz7KwsEhO9bxbyKz8fr7gwfbmo6nsi8gqwHsgDPsTJa7WAOSJyI07i7+eu/4mIzAE+ddcf7ObPCiltmIALK7pTnPuaHq2qB4A2BTNFpA5QYlI33tq9ezfx8fHUrl2bX375hXffeZvrb7zZ67AAaNCgIRs3fsTBgwepXr067733Di1btvI6LFq2Oo1t27aSkbGdpMQklixexMP/LK0+dGTz8/EK55Wiqno/zq1Ag+Xg1NqLW38cEJZm6Yi0qQMdVDUHQFWDk3hVfv35EXGjRo5g3dr32bPnRzp36sBtg4fSp2+/aBVfKj/G9v2ubO67ZzT5+QHy85Uul3Tlgo6V+W4Pn9Nan87FnS/hyv69iYuL55RTTqVvvxJb8qImPj6eMfeO5bZBN5GfH6BX7740beqPC679+Bnz8/Hy++X/oRL16U0krfklNvj04wX4qmOPqaTq8ZW/x8Wdr38e8qf1X5f9wbefnkjV1I0x5nclVmrqoYzSKCJytYiMdZ+fICIVvtrJGGP8qDwXH/lZKBcfTcS52OhK9/nPwJMRi8gYYzwQLxLy5GehNL+cqapniMiHAKr6ozvAlzHGxAyf5+qQhZLUc90RwxRAROph3RKNMTGmSoxk9VCaXx4H5gGJIjIOWM3vZEAvY4wJVay0qZdZU1fVmSLyAU6necG55H9zxCMzxpgoipXeL2UmdRE5ATgAvB48T1W3RTIwY4yJprJufvF7EUqb+iKc9nQBquMMJ/k5zl06jDEmJsRITg+p+eW04OcicgZwS8QiMsYYD0jlL0r1hXJfUaqq6wtufmH8w6+X4/v5pFJOrj87cVWN9+dBi5XeISU5YmrqIjIi6GkV4AxgV8QiMsYYDxwxSR04JuhxHk4b+6uRCccYY7zhl5t1VFapSd296KiWqt4VpXiMMcYTcRW9Y7PPlJjURSReVfPcE6PGGBPTYuWcQWk19fdx2s83iMgC4GVgf8FCVZ0b4diMMSZqjqQ29QTgB6ATv/ZXV8CSujEmZsRIRb3UpJ7o9nz5mF+TeQGfdqAzxpiKqRLGfuoiciwwBWiFky9vwLlo8yXgJGAr0F9Vf3TXHwPcCASAYar6ZkXLLu3UQBzO3a9r4fSAqVVkMsaYmBHmAb3+CyxR1VOA04HNwGhgmao2A5a5zxGRFsAAnKv0uwIT3a0XiuAAABrkSURBVE4qFVJaTX2nqj5Y0R0bY8zvSXyYGtVFpDbQAbgOQFUPAYdEJBXo6K42DUgDRgGpwGxVzQG+EZEtQHvgnYqUX1pNPUZamIwxpmzlqamLyCARWRc0DQraVQrOBZrPiciHIjJFRGoCSaq6E8D9P9FdvxGwPWj7DHdehZRWU7+oojs1xpjfm/J0aVTVScCkEhbH4/QcHKqq74nIf3GbWkpQXMEVPm9ZYk1dVXdXdKd+kblzJzdedw29LruU3j27M3P6NK9DKjT2vjF0PP9s+qT28DqUQlu/+Zr+fVMLp3PPPIMZ05/3OqxCa1al07P7JfTo2pmpk0v6e4qOn3/6idEjb6dfr270792djR99yN69exhyyw30vewShtxyAz/9tDeqMf3tvnvo1OEcLu91WeG8J//3X/r37skVfXtx2803kJ2dFdWYiuOn9zFYGNvUM4AMVX3Pff4KTpLPEpEGTlnSAMgOWj85aPvGwI4Kvw716UhQv+RVvofNrl3ZfL9rF6e2aMn+/fsY0K8v/3n8SU5u2jQcIVbKB+vWcvTRR3PvmFHMnb+w0vsL99sYCATo0qkD02fNoWHDCv8SDFs3sUAgQM/ul/DM5OdISkriz1dczvh/Plap97IyA3r97b7R/PGMNvTq04/c3EP8cvAXnpv6DHXqHMvAG25m2rOT+emnvQy9Y2S5913RAb0KPlN/vWc0r7zm3P5g37591Krl9Gt4ccYLfP3VV9x3/wMV2n84Ls6JxPsIUD2+8s3Fz6/dFvJf0XXtTii1PBFZBdykqp+LyN+Amu6iH1R1vIiMBhJU9W4RaQm8iNOO3hDnJGozVQ1U5HVE7cJYEXkhWmUVqFcvkVNbOMO+16xZi5SUFF/UVADatG1H7Tp1vA6jRO+9+w6Nk5MrldDD6eNNG0lOPpHGyclUrVaNrt26k7ZimSex7Nu3jw/XryO19+UAVK1ajWNq1yY9bTndL0sFoPtlqayMcnxt2rajTpHPVEFCBzh48KDn45v46X0sqopIyFMIhgIzRWQj8EecW4COBzqLyJdAZ/c5qvoJMAf4FFgCDK5oQocKDL0bCvcK1N/MAi50+26iqj0jUW5pvvsug882b+a01qdHu+jfpTffWMSl3fzTNJSdlUX9BvULnycmJbFp40ZPYtmRsZ3jjkvgwbH38OUXn3NKixbcefc97P7hB+rWc8591a2XyI+7/dGC+cR//83CBfOpdcwxTHrW2yZIP72PRYVzmABV3QC0LWZRsecqVXUcMC4cZUeqpt4Y+Al4DPiXO/0c9LhYwWeUw9nWdmD/fu68Yxh3jb7nNzUXU7zc3EOsTFtO5y5dvQ6lkBbTGudVrTMvEODzzz6lb/8BzHhpLjWqH820Zyd7Eksohtw+nCXL0ri0ew9eenGGp7H46X0sSsox+Vmkknpb4APgXmCvqqYBB1V1paquLGkjVZ2kqm1Vte2NNw8qabVyyc3NZcQdw+jW/TIu7twlLPuMdatXpXPKqS05vm5dr0MplJRUn8ydmYXPs7OySExMLGWLyElMSiIxMYlWpzm/+jp17sLnmz8l4fjj+X6Xc+7r+13ZHJeQ4El8Jbm0ew+W/d9ST2Pw0/tYVJgvPvJMRJK6quar6r+B64F7ReQJItTUU0Yc/G3svaSkpHDtdddHu/jfrSWLF9G1W3evw/iNlq1OY9u2rWRkbCf30CGWLF7EBRd28iSWunXrkVi/Ad9u/QaAte+9S5OUpnS4oBOLXp8PwKLX59OhozfxBfv2262Fj1euWM5JTZp4Fwz+eh+LEpGQJz+LSu8XEekOnKuq94S6TTh6v6z/YB3XX3sVzZo3p4o4319D7xjB+R0uqOyuK23UyBGsW/s+e/b8SMLxx3Pb4KH06duvwvsL19t48OBBul7ckYVL/o9jjjmm7A3KEM7P/6r0lTwy/iHy8wP06t2Xm2+5rVL7q0zvly8+28w/Hvwrebm5NGyUzNgHx5Gfn889d48ga+cOkho05OF//ps6dY4t974r2vtl9F0j+GDt2sLP1K1/GcrqVSv5dutWqojQoGFD7h37AIlJSRXaf7janMP9PkJ4er+89OF3If8VXfGnRr7N7DHdpfFI4tO30dc/Ve0epeXj5/HGw5HUX96wI+S/on5/bOjbgxH1JhFjjPEjvzerhMqSujHGEMWLdiLMkroxxmA1dWOMiSmxkdItqRtjDABxVlM3xpjYESM53ZK6McYASIw0wFhSN8YYrKZujDExpYrV1I0xJnZYTd34Sr5fxwlQiAvTXdrDrVq8Py83SWg/xOsQivXj2ie8DiGi/DwMQnlYUjcR5deEbkxRsfJRtaRujDFY7xdjjIkpMdL6EjNj2BhjTKVIOf6FtD+ROBH5UEQWus8TRGSpiHzp/n9c0LpjRGSLiHwuIpdU5nVYUjfGGJw29VCnEN0ObA56PhpYpqrNgGXuc0SkBTAAaAl0BSaKSFyFX0dFNzTGmFhSRSTkqSwi0hjoDkwJmp0KTHMfTwN6Bc2frao5qvoNsAVoX+HXUdENjTEmlkh5JpFBIrIuaBpUZHf/Ae4Ggm+vlaSqOwHc/wvuuN0I2B60XoY7r0LsRKkxxlC+fuqqOgmYVNwyEekBZKvqByLSMYTdFVdwhS88saRujDGEdTz1c4GeItINqA7UFpEZQJaINFDVnSLSAMh2188AkoO2bwzsqGjh1vxijDFQvvaXUqjqGFVtrKon4ZwAXa6qVwMLgIHuagOB+e7jBcAAETlKRJoAzYD3K/oyrKZujDFEZZiA8cAcEbkR2Ab0A1DVT0RkDvApkAcMVtVARQs5IpJ6IBDgyv59SUxK4omJz3gdDpk7d3LvmLv54YfvEanC5f36c9U1A8veMBKxZO5k7D2j+P7776lSpQp9Lu/Pn6++lqcn/o95r77MccclADBk2HDO63CBJzEWWLMqnQnjx5EfyKd3337ceHPRc1PRcf99Y0hPTyMh4XhefW0hAI89OoH0lSuoGl+Vxskn8MA/HqZ27doRKf/p+6/i0g6t2LX7Z9r2ewiAe2/pxg19zmHXj/ucGJ9YwJurPwWgVbOGPHHflRxTszr5+cp5Vz9CzqE8/nRqMpMeuIYaR1XlzTWfcOcjr0Qk3qLG3jeG9JXO8Zs7f2FUygxFJFK6qqYBae7jH4CLSlhvHDAuHGUeEc0vM6e/QErKyV6HUSguPo6Rd4/mtdffYMasl5g960W+2rLFm1ji4hg+chRzFyxm2szZzJk9k6+/cmK56pqBzH7lNWa/8prnCT0QCPDQuAeZ+PQU5i1YxJLFCz07Zj179WHi01N+M++ss8/llXkLeXne65x40kk8OyVylYfpr79L6uAnD5v/vxkrOGvAeM4aML4wocfFVeHZfwxk6LjZtLl8HJfc/F9y85xK4OP3XMGQf8yiVeoDnHxCPbqc2yJiMQdL7dWHp56ZUvaK0Ram5hevRSWpi8h5IjJCRLpEo7xgWZmZrEpPo3ffy6NddInq1Uvk1BYtAahZsxYpKSlkZ2f5IpYmTU4mO8ubWErz8aaNJCefSOPkZKpWq0bXbt1JW7HMk1jatG1H7Tp1fjPvnHPPIz7e+eHbuvUfycrKjFj5a9Z/xe69B0Ja9+KzT+HjL79j0xffAbB7737y85X6dWtzTM3qvLfxGwBeXPg+l3VsHbGYgxV3/Pwg3FeUeiUiSV1E3g96fDPwBHAMcL+IjI5EmSV5ZPxDDL/zLqpU8eePku++y+CzzZs5rfXpXofCju8y+PyzzbRyY3lp1kz69+nJ3/56Dz/t3etpbNlZWdRvUL/weWJSElk+/PIBeG3eq5x3Xoeol3vrgA68/9IYnr7/Ko49pgYAzU5IRBUWPDmYt18cxYiBFwPQMPFYvsveU7jtd1l7aJh4bNRj9hOR0Cc/i1Smqxr0eBDQWVUfALoAV5W0UXCH/qmTi+0CWi4r01aQkJBAi5atKr2vSDiwfz933jGMu0bfQ61atbyN5cB+Rg4fxp2jxlCrVi369b+SBYuXMvuV16hbrx6PPTrB0/i0mG674sO/rsnPPEVcXBzdevSMbrkvr6LFZX/jzAHjyfz+J8aP6ANAfFwc5/wphevvfZ6LbniMnp1Op2P75sV3jPbrmPxREiOtLxE7UVrFHaymCiCqugtAVfeLSF5JGwV36P8lr+Kd7wts+HA9aWnLWb0qnZycHPbv38eYUSN5eMKjld11peXm5jLijmF0634ZF3eOeqvUYbGMHO7EctHFTizH161buLxP337cPuQ2r8IDICmpPpk7f23SyM7KIjExsZQtom/B/HmsSk/jmSnPR/0LJ3v3z4WPn527hrmP3wrAd9l7WPXBFn7Ysx+AJas/4U+nJDNr8VoaBdXMGyUdy85d3v4a85ofKwkVEamaeh3gA2AdkCAi9QFEpBZR/KK7ffidLF2ezhtLlzPh0cdod+ZZvkjoqsrfxt5LSkoK1153veexPHj/fTRJOZmrB/4ay65d2YWPly/7P05u2syL8Aq1bHUa27ZtJSNjO7mHDrFk8SIuuLCTpzEFW7M6neenTuY//3uKGjVqRL38+nV/7WmT2ul0Pv1qJwBL3/6UVs0aUaN6VeLiqnB+m6Zs/jqTzO9/Yt+BHNqfdhIAf+7RnoUrN0Y9bj+JleaXiNTU3U73xckHekeizN+TD9d/wMIF82nWvDn9+6QCMPSOEZzvQQ+TDR+uZ9Hr82narDkDLnfGFxoybDhL3ljEF59tBhEaNmrEvWMfiHpsweLj4xlz71huG3QT+fkBevXuS1OPvmhG3zWCdWvfZ8+eH+lyUQdu+8tQnp0yiUOHDnHrzc4XY+vWp3Pf/Q9GpPxpD1/H+W2aUffYWmxZ8nf+/vRiOrRpRus/NEZV+Xbnbob+YxYAe34+yOMzlrN6xt2oKm+u/oQlqz8BYNhDLzHpgaupcVRV3lrzaWGPmUgbNfLX49e5UwduGzyUPn37RaXs0vg8V4dM/NqOFo7mlyNJIN+fh8vPt7Pz6Uff7lFaAdXjK5+TP9r+c8ifiNOTj/HtB/uIuPjIGGPK4veuiqGypG6MMfi/rTxUltSNMQZL6sYYE1Os+cUYY2KI1dSNMSaGxEhOt6RujDFAzGR1S+rGGENUbpIRFZbUjTGGmKmoW1I3xhggZrK6DRNgjAlJvk+HogA4ulrl206+zDoY8gtsllTDt18B/rxzhDHGRFm4RmkUkWQRWSEim0XkExG53Z2fICJLReRL9//jgrYZIyJbRORzEbmkMq/DkroxxhDWm2TkAXeq6qnAWcBgEWkBjAaWqWozYJn7HHfZAKAl0BWYKCJxFX0dltSNMQbnJhmhTqVR1Z2qut59/DOwGWgEpALT3NWmAb3cx6nAbFXNUdVvgC1A+4q+DkvqxhhD+Zpfgm+96U6Dit+nnAT8CXgPSFLVneAkfqDg1l2NgO1Bm2W48yrEer8YYwzl6/wSfOvNEvfn3OntVeAOVf2plBp+sbeMLUc4v2E1dWOMgbA2qotIVZyEPlNV57qzs0Skgbu8AVBwz8gMIDlo88bAjoq+DEvqxhiDM0pjqP9K3Y9TJZ8KbFbVx4IWLQAGuo8HAvOD5g8QkaNEpAnQDHi/oq/Dml+MMYawjtJ4LnANsElENrjz7gHGA3NE5EZgG9APQFU/EZE5wKc4PWcGq2qgooXbxUfGmJDE+sVHGT/mhPwCGx93lG8vPrKaujHGALEyToAldWOMIXZukhHzJ0rXrEqnZ/dL6NG1M1Mnl9oDKarG3jeGjuefTZ/UHl6H8ht+PV7g39j8GpdfPmOZmTu5+YZr6dOzG3179eDFGS8AsPTNJfTt1YMzWp/KJ59s8jRGCGvnF0/FdFIPBAI8NO5BJj49hXkLFrFk8UK+2rLF67AASO3Vh6eemeJ1GL/h5+Pl19j8Ghf45zMWFxfHiJGjmLtgMS/MnM1Ls2fy1VdbOLlZM/7178c5o01br0MEwjf2i9ciktRF5EwRqe0+riEiD4jI6yIyQUTqRKLM4ny8aSPJySfSODmZqtWq0bVbd9JWLItW8aVq07YdtetE7VCExM/Hy6+x+TUu8M9nrF69RE5t0RKAmjVr0aTJyezKyiIl5WROapLicXS/CtcwAV6LVE39WeCA+/i/QB1ggjvvuQiVeZjsrCzqN6hf+DwxKYmsrKxoFf+74+fj5dfY/BqXX+34LoPPP9tMq9anex3KYaz5pYz9qmqe+7itqt6hqqtV9QGgxK/m4PEUwtE2qcX0ivT7t6yX/Hy8/BqbX+PyowMH9jNy+DBGjhpDrVq1vA7nMLHS/BKp3i8fi8j1qvoc8JGItFXVdSLSHMgtaaPg8RTC0U89Kak+mTszC59nZ2WRmJhYyhZHNj8fL7/G5te4/CY3N5eRw4dxaffLuOjiLl6HU6yyrhT9vYhUTf0m4AIR+QpoAbwjIl8Dk91lUdGy1Wls27aVjIzt5B46xJLFi7jgwk7RKv53x8/Hy6+x+TUuP1FVHrj/PpqknMw1A6/3OpySxUj7S0SvKBWRY3CaW+KBDFUNubExXFeUrkpfySPjHyI/P0Cv3n25+ZbbwrHbShs1cgTr1r7Pnj0/knD88dw2eCh9+vbzOizfHi/wb2x+jSvcn7GKXlH64foPuGHgVTRr1hyp4tQjhwwbTm7uISY89A9+/HE3xxxTmz+ccgoTn5laoTLCcUXp9/vyQn6BdWvF+za12zABxpiQxPowAbv3B0J+gQk143yb1O2KUmOMwf8nQEMV0xcfGWPMkcZq6sYYQ+zU1C2pG2MMsdOl0ZK6McZgNXVjjIkpltSNMSaGWPOLMcbEkFipqVuXRmOMIbyjBIhIVxH5XES2iMjoCIVcLEvqxhgDYcvqIhIHPAlcijP21ZUi0iJSYRdlzS/GGANUCV/7S3tgi6p+DSAis4FU4NNwFVAa3yb16vHhO2shIoPcYX19x6+xWVzl49e4IJyxhbfR2W/HrDw5R0QGAYOCZk0Kei2NgO1ByzKAMysfYWiOlOaXQWWv4hm/xmZxlY9f4wL/xubXuMqkqpNUtW3QFPzlVNyXQ9RGQztSkroxxkRLBpAc9LwxsCNahVtSN8aY8FoLNBORJiJSDRgALIhW4b5tUw8z37TbFcOvsVlc5ePXuMC/sfk1rkpR1TwRGQK8CcQBz6rqJ9Eq37c3yTDGGFN+1vxijDExxJK6McbEkJhP6l5erlsaEXlWRLJF5GOvYykgIskiskJENovIJyJyu9cxFRCR6iLyvoh85Mb2gNcxBROROBH5UEQWeh1LARHZKiKbRGSDiKzzOp4CInKsiLwiIp+5n7WzvY4plsR0m7p7ue4XQGecbkZrgStVNSpXdpVGRDoA+4AXVLWV1/EAiEgDoIGqrheRY4APgF4+OV4C1FTVfSJSFVgN3K6q73ocGgAiMgJoC9RW1R5exwNOUgfaqur3XscSTESmAatUdYrbO+RoVd3jdVyxItZr6oWX66rqIaDgcl3PqWo6sNvrOIKp6k5VXe8+/hnYjHN1nOfUsc99WtWdfFEjEZHGQHdgitex+J2I1AY6AFMBVPWQJfTwivWkXtzlur5IUn4nIicBfwLe8zaSX7lNHBuAbGCpqvoltv8AdwP5XgdShAJvicgH7mXtfpAC7AKec5urpohITa+DiiWxntQ9vVz390pEagGvAneo6k9ex1NAVQOq+kecK/Tai4jnzVYi0gPIVtUPvI6lGOeq6hk4owUOdpv8vBYPnAE8pap/AvYDvjnXFQtiPal7ernu75HbXv0qMFNV53odT3Hcn+tpQFePQwE4F+jptl/PBjqJyAxvQ3Ko6g73/2xgHk5zpNcygIygX1mv4CR5EyaxntQ9vVz398Y9GTkV2Kyqj3kdTzARqScix7qPawAXA595GxWo6hhVbayqJ+F8vpar6tUeh4WI1HRPduM2b3QBPO9ppaqZwHYR+YM76yKiNCTtkSKmhwnw+nLd0ojILKAjUFdEMoD7VXWqt1FxLnANsMltuwa4R1UXexhTgQbANLdHUxVgjqr6pvugDyUB85zvaeKBF1V1ibchFRoKzHQrWl8D13scT0yJ6S6NxhhzpIn15hdjjDmiWFI3xpgYYkndGGNiiCV1Y4yJIZbUjTEmhlhSNyUSkYA7wt/HIvKyiBxdiX09LyKXu4+niEiLUtbtKCLnVKCMrSJSN9T5JezjOhF5IhzlGuMFS+qmNAdV9Y/uKJKHgFuDF7p9xstNVW8qY+THjkC5k7oxxpK6Cd0qoKlbi14hIi/iXKQUJyL/FJG1IrJRRG4B5+pUEXlCRD4VkUVAYsGORCRNRNq6j7uKyHp3nPRl7kBitwLD3V8J57tXk77qlrFWRM51tz1eRN5yB4Z6huLH+imWiLQXkbfdbd8OusIRIFlElogzDv/9Qdtc7Y7pvkFEnqnol5oxkRTTV5Sa8BCReJxBoQquSGwPtFLVb9zR//aqajsROQpYIyJv4Yzw+AfgNJyrGz8Fni2y33rAZKCDu68EVd0tIk8D+1T1UXe9F4F/q+pqETkB5wrhU4H7gdWq+qCIdAfKMxLhZ265eSJyMfAQ0Df49QEHgLXul9J+4AqcQbJyRWQicBXwQjnKNCbiLKmb0tQIGi5gFc64MOcA76vqN+78LkDrgvZyoA7QDGfM7FmqGgB2iMjyYvZ/FpBesC9VLWl8+YuBFu4l7wC13XFNOgB93G0XiciP5XhtdXCGHWiGM3Jn1aBlS1X1BwARmQucB+QBbXCSPEANnCGAjfEVS+qmNAfdoW4LuQltf/AsYKiqvllkvW6UPcyxhLAOOM2EZ6vqwWJiqeg4F38HVqhqb7fJJy1oWdF9qhvrNFUdU8HyjIkKa1M3lfUmcJs7ZC8i0twdFTAdGOC2uTcALixm23eAC0Skibttgjv/Z+CYoPXeAoYUPBGRgi+adJwmEETkUuC4csRdB/jOfXxdkWWdRSTBHQ2yF7AGWAZcLiKJBbGKyInlKM+YqLCkbiprCk57+XpxbqL9DM4vwHnAl8Am4ClgZdENVXUXTjv4XBH5CHjJXfQ60LvgRCkwDGjrnoj9lF974TwAdBCR9TjNQNtKiXOjiGS402PAI8DDIrIGZwTPYKuB6cAG4FVVXef21rkP505CG4GlOCNHGuMrNkqjMcbEEKupG2NMDLGkbowxMcSSujHGxBBL6sYYE0MsqRtjTAyxpG6MMTHEkroxxsSQ/weKar3B6GFNyAAAAABJRU5ErkJggg==\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"# Extract the row and column corresponding to class 4: mel\nclass_idx = 4\nfn = conf_matrix[class_idx, :].sum() - conf_matrix[class_idx, class_idx]\n\n# Calculate the percentage of instances from class 4 that were classified as another class\nfn_percent = (fn / conf_matrix[class_idx, :].sum()) * 100\n\n# Print the results\nprint(f\"False Negative Rate for mel: {fn_percent:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2023-05-16T22:14:22.725362Z","iopub.execute_input":"2023-05-16T22:14:22.725740Z","iopub.status.idle":"2023-05-16T22:14:22.732820Z","shell.execute_reply.started":"2023-05-16T22:14:22.725700Z","shell.execute_reply":"2023-05-16T22:14:22.731515Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"False Negative Rate for mel: 27.71%\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}