{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### Versions:\n* v9: ColorJitter transformation added [0.896]\n* v10: Changed the dataset to [this one](https://www.kaggle.com/shonenkov/melanoma-merged-external-data-512x512-jpeg) with external data. [0.894]\n* v11: Switched to [another dataset](https://www.kaggle.com/nroman/melanoma-external-malignant-256/) which I've created by myself. Also switched from StratifiedKFold to GroupKFold [0.916]\n* v12: Switched to efficientnet-b1 [0.919]\n* v13: Using meta featues: sex and age [0.918]\n* v14: anatom_site_general_challenge meta feature added as one-hot encoded matrix [0.923]\n* v16: Fixed OOF - now it contains only data from original training dataset, without extarnal data. Also switched back to StratifiedKFold. Added DrawHair augmentation. [0.909]\n* v18: Too many things were changed at the same time. All experiments should have only one small change each, so it would be easy to understand how changes affect the result. Said that I rolled back everything, keeping only OOF fix, to make sure it work.\n* v19: Added 'Hair' augmentation. OOF rework posponed untill the best time, since there is some bug in my code for it.","metadata":{}},{"cell_type":"code","source":"!pip install efficientnet_pytorch torchtoolbox","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-05-19T12:06:25.103301Z","iopub.execute_input":"2023-05-19T12:06:25.103654Z","iopub.status.idle":"2023-05-19T12:06:36.228654Z","shell.execute_reply.started":"2023-05-19T12:06:25.103611Z","shell.execute_reply":"2023-05-19T12:06:36.227504Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting efficientnet_pytorch\n  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\nCollecting torchtoolbox\n  Downloading torchtoolbox-0.1.8.2-py3-none-any.whl (84 kB)\n\u001b[K     |████████████████████████████████| 84 kB 2.2 MB/s eta 0:00:011\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet_pytorch) (1.5.0)\nRequirement already satisfied: pyarrow in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (0.16.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (1.18.1)\nRequirement already satisfied: prettytable in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (0.7.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (1.4.1)\nCollecting lmdb\n  Downloading lmdb-1.4.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (294 kB)\n\u001b[K     |████████████████████████████████| 294 kB 29.2 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (4.2.0.34)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (2.9.0)\nRequirement already satisfied: tensorboard in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (2.1.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (0.22.2.post1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (1.14.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (4.45.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from torchtoolbox) (5.3.1)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet_pytorch) (0.18.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers->torchtoolbox) (2.23.0)\nRequirement already satisfied: tokenizers==0.7.0 in /opt/conda/lib/python3.7/site-packages (from transformers->torchtoolbox) (0.7.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers->torchtoolbox) (2020.4.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers->torchtoolbox) (3.0.10)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from transformers->torchtoolbox) (0.1.86)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers->torchtoolbox) (0.0.43)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (0.4.1)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (0.9.0)\nRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (0.34.2)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (46.1.3.post20200325)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (1.0.1)\nRequirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (1.28.1)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (3.2.1)\nRequirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (3.11.4)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->torchtoolbox) (1.14.0)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->torchtoolbox) (0.14.1)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers->torchtoolbox) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers->torchtoolbox) (2020.4.5.1)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers->torchtoolbox) (2.9)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers->torchtoolbox) (1.24.3)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers->torchtoolbox) (7.1.1)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->torchtoolbox) (1.2.0)\nRequirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->torchtoolbox) (4.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->torchtoolbox) (0.2.7)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->torchtoolbox) (3.1.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->torchtoolbox) (3.0.1)\nRequirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard->torchtoolbox) (0.4.8)\nBuilding wheels for collected packages: efficientnet-pytorch\n  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=5e8b839260b47b630b855e87bbcf6245196cd21ae1107033bafbc5cab07c85cb\n  Stored in directory: /root/.cache/pip/wheels/0e/cc/b2/49e74588263573ff778da58cc99b9c6349b496636a7e165be6\nSuccessfully built efficientnet-pytorch\nInstalling collected packages: efficientnet-pytorch, lmdb, torchtoolbox\nSuccessfully installed efficientnet-pytorch-0.7.1 lmdb-1.4.1 torchtoolbox-0.1.8.2\n\u001b[33mWARNING: You are using pip version 20.1; however, version 23.1.2 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torchvision\nfrom torchvision import models,transforms\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom torchvision import transforms\nfrom torch.utils.data.sampler import RandomSampler, SequentialSampler\n\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold\nimport pandas as pd\nimport numpy as np\nimport gc\nimport os\nimport cv2\nimport time\nimport datetime\nimport warnings\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom efficientnet_pytorch import EfficientNet\n\nfrom sklearn.model_selection import train_test_split\n\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-19T12:06:36.231295Z","iopub.execute_input":"2023-05-19T12:06:36.231811Z","iopub.status.idle":"2023-05-19T12:06:39.008493Z","shell.execute_reply.started":"2023-05-19T12:06:36.231698Z","shell.execute_reply":"2023-05-19T12:06:39.007699Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-19T12:06:39.009937Z","iopub.execute_input":"2023-05-19T12:06:39.010304Z","iopub.status.idle":"2023-05-19T12:06:39.015127Z","shell.execute_reply.started":"2023-05-19T12:06:39.010260Z","shell.execute_reply":"2023-05-19T12:06:39.014224Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# At least fixing some random seeds. \n# It is still impossible to make results 100% reproducible when using GPU\nwarnings.simplefilter('ignore')\ntorch.manual_seed(47)\nnp.random.seed(47)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T12:06:39.016504Z","iopub.execute_input":"2023-05-19T12:06:39.017212Z","iopub.status.idle":"2023-05-19T12:06:39.028216Z","shell.execute_reply.started":"2023-05-19T12:06:39.017170Z","shell.execute_reply":"2023-05-19T12:06:39.027275Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-05-19T12:06:39.031720Z","iopub.execute_input":"2023-05-19T12:06:39.032122Z","iopub.status.idle":"2023-05-19T12:06:39.058847Z","shell.execute_reply.started":"2023-05-19T12:06:39.032086Z","shell.execute_reply":"2023-05-19T12:06:39.057829Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class MelanomaDataset(Dataset):\n    def __init__(self, df: pd.DataFrame, train: bool = True, transforms = None, meta_features = None):\n        \"\"\"\n        Class initialization\n        Args:\n            df (pd.DataFrame): DataFrame with data description\n            imfolder (str): folder with images\n            train (bool): flag of whether a training dataset is being initialized or testing one\n            transforms: image transformation method to be applied\n            meta_features (list): list of features with meta information, such as sex and age\n            \n        \"\"\"\n        self.df = df\n        self.path1 = '/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1'\n        self.path2 = '/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2'\n        self.transforms = transforms\n        self.train = train\n        self.meta_features = meta_features\n        \n    def __getitem__(self, index):\n        image_path = os.path.join(self.path1, self.df.iloc[index]['image_id'] + '.jpg')\n        if os.path.exists(image_path):\n            image = cv2.imread(image_path)\n        else:\n            # If the image is not in part 1, try to load it from part 2\n            image_path = os.path.join(self.path2, self.df.iloc[index]['image_id'] + '.jpg')\n            if os.path.exists(image_path):\n                image = cv2.imread(image_path)\n                \n        meta = np.array(self.df.iloc[index][self.meta_features].values, dtype=np.float32)\n\n        if self.transforms:\n            x = self.transforms(image)\n            \n        if self.train:\n            y = self.df.iloc[index]['target']\n            return (x, meta), y\n        else:\n            return (x, meta)\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def _get_label(self, dataset, idx):\n        return self.df.iloc[idx]['target']\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-19T12:06:39.063553Z","iopub.execute_input":"2023-05-19T12:06:39.065419Z","iopub.status.idle":"2023-05-19T12:06:39.080895Z","shell.execute_reply.started":"2023-05-19T12:06:39.065377Z","shell.execute_reply":"2023-05-19T12:06:39.079882Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n])\ntest_transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n])\n","metadata":{"execution":{"iopub.status.busy":"2023-05-19T12:06:39.082369Z","iopub.execute_input":"2023-05-19T12:06:39.082764Z","iopub.status.idle":"2023-05-19T12:06:39.097101Z","shell.execute_reply.started":"2023-05-19T12:06:39.082704Z","shell.execute_reply":"2023-05-19T12:06:39.096154Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"skf = GroupKFold(n_splits=3)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T12:06:39.098442Z","iopub.execute_input":"2023-05-19T12:06:39.099059Z","iopub.status.idle":"2023-05-19T12:06:39.118548Z","shell.execute_reply.started":"2023-05-19T12:06:39.098988Z","shell.execute_reply":"2023-05-19T12:06:39.117824Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# df = pd.read_csv('/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv')\n# df = pd.read_csv('/kaggle/input/meta-abcd/metadata_ABCD.csv')\ndf = pd.read_csv('/kaggle/input/metadata-fromcnn/metadata_fromCNN.csv')\n\n\n# this will tell us how many images are associated with each lesion_id\ndf_undup = df.groupby('lesion_id').count()\n# now we filter out lesion_id's that have only one image associated with it\ndf_undup = df_undup[df_undup['image_id'] == 1]\ndf_undup.reset_index(inplace=True)\n\ndef get_duplicates(x):\n    unique_list = list(df_undup['lesion_id'])\n    if x in unique_list:\n        return 'unduplicated'\n    else:\n        return 'duplicated'\n\n# create a new colum that is a copy of the lesion_id column\ndf['duplicates'] = df['lesion_id']\n# apply the function to this new column\ndf['duplicates'] = df['duplicates'].apply(get_duplicates)\n\ndf_undup  = df[df['duplicates'] == 'unduplicated']\n\n#now we create a test set using df_undup because we are sure that none of these images have augmented duplicates in the train set\ny = df_undup['dx']\n_, test_df_csv = train_test_split(df_undup, test_size=0.36325, random_state=101, stratify=y)\ntest_df_csv.shape\n\n# This set will be df_original excluding all rows that are in the test set\n# This function identifies if an image is part of the train or test set.\ndef get_test_rows(x):\n    # create a list of all the lesion_id's in the val test\n    test_list = list(test_df_csv['image_id'])\n    if str(x) in test_list:\n        return 'test'\n    else:\n        return 'train'\n\n# identify train and test rows\n# create a new colum that is a copy of the image_id column\ndf['train_or_test'] = df['image_id']\n# apply the function to this new column\ndf['train_or_test'] = df['train_or_test'].apply(get_test_rows)\n# filter out train rows\ntrain_df_csv = df[df['train_or_test'] == 'train']\n\n# Split the test into 50% test and 50% validation\n# test_df, val_df = train_test_split(test_df_csv, test_size=0.5, random_state=101, stratify=test_df_csv['dx'])\n\ntrain_df = train_df_csv\ntest_df = test_df_csv\nprint(len(train_df))\nprint(len(test_df))","metadata":{"execution":{"iopub.status.busy":"2023-05-19T12:06:39.119827Z","iopub.execute_input":"2023-05-19T12:06:39.120267Z","iopub.status.idle":"2023-05-19T12:06:50.180627Z","shell.execute_reply.started":"2023-05-19T12:06:39.120220Z","shell.execute_reply":"2023-05-19T12:06:50.178064Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"8012\n2003\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df_csv.dx.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-05-19T12:06:50.185997Z","iopub.execute_input":"2023-05-19T12:06:50.190450Z","iopub.status.idle":"2023-05-19T12:06:50.212975Z","shell.execute_reply.started":"2023-05-19T12:06:50.190370Z","shell.execute_reply":"2023-05-19T12:06:50.211791Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"nv       5101\nmel      1030\nbkl       939\nbcc       450\nakiec     272\nvasc      119\ndf        101\nName: dx, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ntrain_df['target'] = le.fit_transform(train_df['dx'])\ntest_df['target'] = le.fit_transform(test_df['dx'])","metadata":{"execution":{"iopub.status.busy":"2023-05-19T12:06:50.217124Z","iopub.execute_input":"2023-05-19T12:06:50.217545Z","iopub.status.idle":"2023-05-19T12:06:50.235023Z","shell.execute_reply.started":"2023-05-19T12:06:50.217499Z","shell.execute_reply":"2023-05-19T12:06:50.234136Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_df.target.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-05-19T12:06:50.239581Z","iopub.execute_input":"2023-05-19T12:06:50.240881Z","iopub.status.idle":"2023-05-19T12:06:50.251366Z","shell.execute_reply.started":"2023-05-19T12:06:50.240836Z","shell.execute_reply":"2023-05-19T12:06:50.250261Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"5    5101\n4    1030\n2     939\n1     450\n0     272\n6     119\n3     101\nName: target, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# from collections import Counter\n# from sklearn.utils import resample\n\n# data_aug_rate = [14, 9, 4, 49, 4, 0, 39]\n\n# for i in range(7):\n#     if data_aug_rate[i] and i != train_df['target'].mode()[0]:\n#         X_subset = train_df[train_df['target'] == i].drop(['target'], axis=1)\n#         y_subset = train_df[train_df['target'] == i]['target']\n#         X_subset_resampled, y_subset_resampled = resample(X_subset, y_subset, \n#                                                           replace=True, n_samples=data_aug_rate[i]*len(X_subset), \n#                                                           random_state=42)\n#         train_df = pd.concat([train_df, pd.concat([X_subset_resampled, y_subset_resampled], axis=1)])\n        \n# train_df['target'].value_counts()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-19T12:06:50.252938Z","iopub.execute_input":"2023-05-19T12:06:50.253535Z","iopub.status.idle":"2023-05-19T12:06:50.260420Z","shell.execute_reply.started":"2023-05-19T12:06:50.253491Z","shell.execute_reply":"2023-05-19T12:06:50.259358Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# data_aug_rate = [15,10,5,50,5,0,40]\n# for i in range(7):\n#     if data_aug_rate[i]:\n#         train_df=train_df.append([train_df.loc[train_df['target'] == i,:]]*(data_aug_rate[i]-1), ignore_index=True)\n# train_df['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-05-19T12:06:50.261933Z","iopub.execute_input":"2023-05-19T12:06:50.262579Z","iopub.status.idle":"2023-05-19T12:06:50.275068Z","shell.execute_reply.started":"2023-05-19T12:06:50.262529Z","shell.execute_reply":"2023-05-19T12:06:50.273854Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_df['sex'] = train_df['sex'].map({'male': 1, 'female': 0})\ntest_df['sex'] = test_df['sex'].map({'male': 1, 'female': 0})\ntrain_df['sex'] = train_df['sex'].fillna(-1)\ntest_df['sex'] = test_df['sex'].fillna(-1)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-19T12:06:50.276623Z","iopub.execute_input":"2023-05-19T12:06:50.277183Z","iopub.status.idle":"2023-05-19T12:06:50.295375Z","shell.execute_reply.started":"2023-05-19T12:06:50.277143Z","shell.execute_reply":"2023-05-19T12:06:50.294536Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"imp_mean=(train_df[\"age\"].sum())/(train_df[\"age\"].count()-train_df[\"age\"].isna().sum())\ntrain_df['age']=train_df['age'].fillna(imp_mean)\ntrain_df['age'].head()\nimp_mean_test=(test_df[\"age\"].sum())/(test_df[\"age\"].count())\ntest_df['age']=test_df['age'].fillna(imp_mean_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T12:06:50.298721Z","iopub.execute_input":"2023-05-19T12:06:50.299012Z","iopub.status.idle":"2023-05-19T12:06:50.308911Z","shell.execute_reply.started":"2023-05-19T12:06:50.298982Z","shell.execute_reply":"2023-05-19T12:06:50.308119Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_df = pd.get_dummies(train_df, columns=['localization'],prefix='site')\ntest_df = pd.get_dummies(test_df, columns=['localization'],prefix='site')\n\n# adding missing cols to testset\ntest_df = test_df.reindex(columns=train_df.columns, fill_value=0)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T12:06:50.310122Z","iopub.execute_input":"2023-05-19T12:06:50.310705Z","iopub.status.idle":"2023-05-19T12:06:50.355869Z","shell.execute_reply.started":"2023-05-19T12:06:50.310665Z","shell.execute_reply":"2023-05-19T12:06:50.354843Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# meta_features = ['sex', 'age'] + [col for col in train_df.columns if 'site_' in col]\nmeta_features = ['age', 'sex'] + [col for col in train_df.columns if 'site_' in col]","metadata":{"execution":{"iopub.status.busy":"2023-05-19T12:06:50.357336Z","iopub.execute_input":"2023-05-19T12:06:50.357855Z","iopub.status.idle":"2023-05-19T12:06:50.363256Z","shell.execute_reply.started":"2023-05-19T12:06:50.357813Z","shell.execute_reply":"2023-05-19T12:06:50.362198Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"cnn = list(range(0,256))\n# abcd = list(range(0,6))","metadata":{"execution":{"iopub.status.busy":"2023-05-19T12:06:50.365219Z","iopub.execute_input":"2023-05-19T12:06:50.365994Z","iopub.status.idle":"2023-05-19T12:06:50.373973Z","shell.execute_reply.started":"2023-05-19T12:06:50.365950Z","shell.execute_reply":"2023-05-19T12:06:50.373083Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# cnn only\n# meta_features = cnn\n\n# meta_features = abcd             '''uncomment for cnn only'''\nmeta_features = meta_features + cnn","metadata":{"execution":{"iopub.status.busy":"2023-05-19T12:06:50.375680Z","iopub.execute_input":"2023-05-19T12:06:50.376409Z","iopub.status.idle":"2023-05-19T12:06:50.383352Z","shell.execute_reply.started":"2023-05-19T12:06:50.376367Z","shell.execute_reply":"2023-05-19T12:06:50.382405Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"meta_features = [str(x) for x in meta_features]","metadata":{"execution":{"iopub.status.busy":"2023-05-19T12:06:50.384594Z","iopub.execute_input":"2023-05-19T12:06:50.385234Z","iopub.status.idle":"2023-05-19T12:06:50.409334Z","shell.execute_reply.started":"2023-05-19T12:06:50.385194Z","shell.execute_reply":"2023-05-19T12:06:50.408474Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"len(meta_features)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T12:06:50.412058Z","iopub.execute_input":"2023-05-19T12:06:50.412694Z","iopub.status.idle":"2023-05-19T12:06:50.421713Z","shell.execute_reply.started":"2023-05-19T12:06:50.412652Z","shell.execute_reply":"2023-05-19T12:06:50.420895Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"273"},"metadata":{}}]},{"cell_type":"code","source":"#meta_features","metadata":{"execution":{"iopub.status.busy":"2023-05-19T12:06:50.423485Z","iopub.execute_input":"2023-05-19T12:06:50.424238Z","iopub.status.idle":"2023-05-19T12:06:50.431152Z","shell.execute_reply.started":"2023-05-19T12:06:50.424191Z","shell.execute_reply":"2023-05-19T12:06:50.430077Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"test = MelanomaDataset(df=test_df,\n                       train=False,\n                       transforms=test_transform,\n                        meta_features=meta_features)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T12:06:50.432954Z","iopub.execute_input":"2023-05-19T12:06:50.433668Z","iopub.status.idle":"2023-05-19T12:06:50.441687Z","shell.execute_reply.started":"2023-05-19T12:06:50.433580Z","shell.execute_reply":"2023-05-19T12:06:50.440579Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self, output_size, no_columns, b1=False, b4=False):\n        super().__init__()\n        self.no_columns = no_columns\n        \n        self.b1 = b1\n        self.b4 = b4\n        \n        if self.b1:\n            self.features = EfficientNet.from_pretrained('efficientnet-b1')\n            self.classification = nn.Sequential(nn.Linear(1280 + 16, output_size))\n        elif self.b4:\n            self.features = EfficientNet.from_pretrained('efficientnet-b4')\n            self.classification = nn.Sequential(nn.Linear(1792 + 16, output_size))\n        \n        \n        # (CSV)\n        self.csv = nn.Sequential(nn.Linear(self.no_columns, 32),\n                                 nn.BatchNorm1d(32),\n                                 nn.ReLU(),\n                                 nn.Dropout(p=0.3),\n                                 \n                                 nn.Linear(32, 16),\n                                 nn.BatchNorm1d(16),\n                                 nn.ReLU(),\n                                 nn.Dropout(p=0.2))\n          \n        \n        \n    def forward(self, image, csv_data, prints=False):    \n        \n        if prints: print('Input Image shape:', image.shape, '\\n'+\n                         'Input csv_data shape:', csv_data.shape)\n        \n        # IMAGE CNN\n        image = self.features.extract_features(image)\n        if prints: print('Features Image shape:', image.shape)\n\n        if self.b1:\n            image = F.avg_pool2d(image, image.size()[2:]).reshape(-1, 1280)\n        elif self.b4:\n            image = F.avg_pool2d(image, image.size()[2:]).reshape(-1, 1792)\n     \n        if prints: print('Image Reshaped shape:', image.shape)\n            \n        # CSV FNN\n        csv_data = self.csv(csv_data)\n        if prints: print('CSV Data:', csv_data.shape)\n            \n        # Concatenate\n        image_csv_data = torch.cat((image, csv_data), dim=1)\n        \n#         image_csv_data = F.relu(image_csv_data)\n        \n        # CLASSIF\n        out = self.classification(image_csv_data)\n        if prints: print('Out shape:', out.shape)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2023-05-19T12:06:50.443671Z","iopub.execute_input":"2023-05-19T12:06:50.444538Z","iopub.status.idle":"2023-05-19T12:06:50.467388Z","shell.execute_reply.started":"2023-05-19T12:06:50.444488Z","shell.execute_reply":"2023-05-19T12:06:50.466037Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"epochs = 10 # Number of epochs to run\nmodel_path = 'model.pth'  # Path and filename to save model to\nes_patience = 3  # Early Stopping patience - for how many epochs with no improvements to wait\nTTA = 3 # Test Time Augmentation \n\noof = np.zeros((len(train_df), 7))  # Out Of Fold predictions\n","metadata":{"execution":{"iopub.status.busy":"2023-05-19T12:06:50.469149Z","iopub.execute_input":"2023-05-19T12:06:50.469829Z","iopub.status.idle":"2023-05-19T12:06:50.480292Z","shell.execute_reply.started":"2023-05-19T12:06:50.469779Z","shell.execute_reply":"2023-05-19T12:06:50.479430Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nimport tqdm.notebook as tq\nimport torch.nn.functional as F\nfrom sklearn.utils.class_weight import compute_class_weight","metadata":{"execution":{"iopub.status.busy":"2023-05-19T12:06:50.482068Z","iopub.execute_input":"2023-05-19T12:06:50.482796Z","iopub.status.idle":"2023-05-19T12:06:50.489529Z","shell.execute_reply.started":"2023-05-19T12:06:50.482674Z","shell.execute_reply":"2023-05-19T12:06:50.488630Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"train_df.columns[train_df.isnull().any()]","metadata":{"execution":{"iopub.status.busy":"2023-05-19T12:06:50.491271Z","iopub.execute_input":"2023-05-19T12:06:50.491642Z","iopub.status.idle":"2023-05-19T12:06:50.524965Z","shell.execute_reply.started":"2023-05-19T12:06:50.491602Z","shell.execute_reply":"2023-05-19T12:06:50.523850Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"Index([], dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"# Define Focal loss implementation\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=2, alpha=None, reduction='mean'):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n        self.reduction = reduction\n\n    def forward(self, inputs, targets):\n        CE_loss = F.cross_entropy(inputs, targets, reduction=self.reduction, weight=self.alpha)\n        pt = torch.exp(-CE_loss)\n        F_loss = ((1-pt)**self.gamma) * CE_loss\n        if self.reduction == 'mean': return F_loss.mean()\n        else: return F_loss.sum()","metadata":{"execution":{"iopub.status.busy":"2023-05-19T12:06:50.528856Z","iopub.execute_input":"2023-05-19T12:06:50.529146Z","iopub.status.idle":"2023-05-19T12:06:50.538943Z","shell.execute_reply.started":"2023-05-19T12:06:50.529116Z","shell.execute_reply":"2023-05-19T12:06:50.538030Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"import gc\n\nfrom sklearn.metrics import accuracy_score, precision_score,recall_score, f1_score\n\nfrom sklearn.preprocessing import LabelBinarizer\n\nfrom sklearn.metrics import confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2023-05-19T12:06:50.541163Z","iopub.execute_input":"2023-05-19T12:06:50.541561Z","iopub.status.idle":"2023-05-19T12:06:50.549628Z","shell.execute_reply.started":"2023-05-19T12:06:50.541519Z","shell.execute_reply":"2023-05-19T12:06:50.548524Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"\n# We stratify by target value, thus, according to sklearn StratifiedKFold documentation\n# We can fill `X` with zeroes of corresponding length to use it as a placeholder\n# since we only need `y` to stratify the data\n# for fold, (train_idx, val_idx) in enumerate(skf.split(X=np.zeros(len(train_df)), y=train_df['target']), 1):\nfor fold, (train_idx, val_idx) in enumerate(skf.split(X=np.zeros(len(train_df)), y=train_df['target'], groups=train_df['lesion_id'].tolist()), 1):\n    print('=' * 20, 'Fold', fold, '=' * 20)\n    \n    best_val = None  # Best validation score within this fold\n    patience = es_patience  # Current patience counter\n#     arch = EfficientNet.from_pretrained('efficientnet-b1')\n#     arch = models.resnet50(pretrained=True)\n#     model = Net(arch=arch, n_meta_features=len(meta_features))  # New model for each fold\n    \n    model = Net(output_size = 7 , no_columns=len(meta_features), b1=True)\n    model = model.to(device)\n    \n    \n    optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n    scheduler = ReduceLROnPlateau(optimizer=optim, mode='max', patience=1, verbose=True, factor=0.4)\n    criterion = nn.CrossEntropyLoss()\n    \n    # Get the class weights for the training data\n    #class_weights1 = torch.tensor(compute_class_weight('balanced', classes=np.unique(train_df.iloc[train_idx]['target']), y=train_df.iloc[train_idx]['target']), dtype=torch.float32)\n    #class_weights = class_weights1.to(device)\n    \n    #giving more importance to mel\n    \n    # Define weight factors\n    class_factor_interest = 2.0\n    class_factor_minority = 1.0\n    class_factor_majority = 0.5\n\n    # Get class labels and weights\n    class_labels = np.unique(train_df.iloc[train_idx]['target'])\n    class_weights_all = compute_class_weight('balanced', classes=class_labels, y=train_df.iloc[train_idx]['target'])\n\n    # Modify class weights to reflect weight factors\n    class_weights = np.zeros_like(class_weights_all)\n    for i, weight in enumerate(class_weights_all):\n        if class_labels[i] == 4:  # class of interest\n            class_weights[i] = weight * class_factor_interest\n        elif weight == np.max(class_weights_all):  # majority class\n            class_weights[i] = weight * class_factor_majority\n        else:  # minority class\n            class_weights[i] = weight * class_factor_minority\n\n    # Convert class weights to PyTorch tensor\n    class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n    \n    \n    \n    focal_loss = FocalLoss(gamma=2, alpha=class_weights)\n\n    train = MelanomaDataset(df=train_df.iloc[train_idx].reset_index(drop=True), \n                            train=True, \n                            transforms=train_transform,\n                            meta_features=meta_features)\n    val = MelanomaDataset(df=train_df.iloc[val_idx].reset_index(drop=True), \n                            train=True, \n                            transforms=test_transform,\n                            meta_features=meta_features)   \n\n    train_loader = DataLoader(dataset=train, batch_size=16, shuffle=True, num_workers=0)\n    val_loader = DataLoader(dataset=val, batch_size=8, shuffle=False, num_workers=0)\n    test_loader = DataLoader(dataset=test, batch_size=8, shuffle=False, num_workers=0)\n    \n    for epoch in tqdm(range(epochs)):\n        start_time = time.time()\n        correct = 0\n        epoch_loss = 0\n        model.train()\n        \n        for x, y in tq.tqdm(train_loader):\n            x[0] = torch.tensor(x[0], device=device, dtype=torch.float32)\n            x[1] = torch.tensor(x[1], device=device, dtype=torch.float32)\n            y = torch.tensor(y, device=device, dtype=torch.long)\n            \n            optim.zero_grad()\n#             z = model(x)\n            z = model(x[0],x[1])\n            loss = focal_loss(z, y)\n            loss.backward()\n            optim.step()\n            pred = torch.argmax(z, dim=1)  # get the index of the highest value in out\n            correct += (pred.cpu() == y.cpu()).sum().item()  # tracking number of correctly predicted samples\n            epoch_loss += loss.item()\n        train_acc = correct / len(train_idx)\n\n        model.eval()  # switch model to the evaluation mode\n        val_preds = torch.zeros((len(val_idx), 7), dtype=torch.float32, device=device)\n        with torch.no_grad():  # Do not calculate gradient since we are only predicting\n            # Predicting on validation set\n            for j, (x_val, y_val) in enumerate(val_loader):\n                x_val[0] = torch.tensor(x_val[0], device=device, dtype=torch.float32)\n                x_val[1] = torch.tensor(x_val[1], device=device, dtype=torch.float32)\n                y_val = torch.tensor(y_val, device=device, dtype=torch.long)\n#                 z_val = model(x_val)\n                z_val = model(x_val[0],x_val[1])\n                val_pred = torch.sigmoid(z_val)\n                val_preds[j*x_val[0].shape[0]:j*x_val[0].shape[0] + x_val[0].shape[0]] = val_pred\n            \n            val_preds = torch.softmax(val_preds, dim=1) # use softmax to convert logits to probabilities\n            val_acc = accuracy_score(train_df.iloc[val_idx]['target'].values, torch.argmax(val_preds.cpu(), dim=1))\n            val_preds = val_preds.cpu().detach().numpy()\n            val_preds = val_preds.reshape(-1, 7) # reshape val_preds to a 2D tensor\n            \n            val_roc = roc_auc_score(train_df.iloc[val_idx]['target'].values, val_preds, multi_class='ovr')\n            \n            print('Epoch {:03}: | Loss: {:.3f} | Train acc: {:.3f} | Val acc: {:.3f} | Val roc_auc: {:.3f} | Training time: {}'.format(\n            epoch + 1, \n            epoch_loss/len(train_loader), \n            train_acc, \n            val_acc, \n            val_roc, \n            str(datetime.timedelta(seconds=time.time() - start_time))[:7]))\n            \n            scheduler.step(val_roc)\n            # During the first iteration (first epoch) best validation is set to None\n            if not best_val:\n                best_val = val_roc  # So any validation roc_auc we have is the best one for now\n                torch.save(model, model_path)  # Saving the model\n                continue\n                \n            if val_roc >= best_val:\n                best_val = val_roc\n                patience = es_patience  # Resetting patience since we have new best validation accuracy\n                torch.save(model, model_path)  # Saving current best model\n            else:\n                patience -= 1\n                if patience == 0:\n                    print('Early stopping. Best Val roc_auc: {:.3f}'.format(best_val))\n                    break\n                    \n    gc.collect()\n    torch.cuda.empty_cache()\n    \n    #Testing the fold results\n    model = torch.load('/kaggle/working/model.pth')\n    model.eval()  # switch model to the evaluation mode\n    preds = torch.zeros((len(test), 7), dtype=torch.float32, device=device)\n    with torch.no_grad():\n\n        for i, x_test in enumerate(test_loader):\n            x_test[0] = torch.tensor(x_test[0], device=device, dtype=torch.float32)\n            x_test[1] = torch.tensor(x_test[1], device=device, dtype=torch.float32)\n    #         z_test = model(x_test)\n            z_test = model(x_test[0],x_test[1])\n            z_test = torch.softmax(z_test, dim=1) # use softmax to convert logits to probabilities\n            preds[i*x_test[0].shape[0]:i*x_test[0].shape[0] + x_test[0].shape[0]] += z_test\n\n\n\n    gc.collect()   \n        \n    # Convert the target data to one-hot encoded format\n    lb = LabelBinarizer()\n    test_labels = lb.fit_transform(test_df['target'])\n\n    # Get predictions for the test set\n    test_preds = preds.cpu()\n\n    # Convert the predictions to one-hot encoded format if needed\n    if len(test_preds.shape) > 1 and test_preds.shape[1] > 1:\n        test_preds = np.argmax(test_preds, axis=1)\n        test_preds = lb.transform(test_preds)\n\n    # Calculate metrics\n    acc = accuracy_score(test_labels, test_preds)\n    prec = precision_score(test_labels, test_preds, average='macro')\n    rec = recall_score(test_labels, test_preds, average='macro')\n    f1 = f1_score(test_labels, test_preds, average='macro')\n    roc = roc_auc_score(test_labels, test_preds, multi_class='ovr')\n    \n    print(\"acc \", acc)\n    print(\"prec \",prec)\n    print(\"rec \",rec)\n    print(\"f1 \",f1)\n    print(\"roc \",roc)\n\n    conf_matrix = confusion_matrix(test_labels.argmax(axis=1), test_preds.argmax(axis=1))\n    \n    # Extract the row and column corresponding to class 4: mel\n    class_idx = 4\n    fn = conf_matrix[class_idx, :].sum() - conf_matrix[class_idx, class_idx]\n\n    # Calculate the percentage of instances from class 4 that were classified as another class\n    fn_percent = (fn / conf_matrix[class_idx, :].sum()) * 100\n\n    # Print the results\n    print(f\"False Negative Rate for mel: {fn_percent:.2f}%\")\n\n                ","metadata":{"execution":{"iopub.status.busy":"2023-05-19T12:06:50.551474Z","iopub.execute_input":"2023-05-19T12:06:50.551942Z","iopub.status.idle":"2023-05-19T15:08:18.107448Z","shell.execute_reply.started":"2023-05-19T12:06:50.551901Z","shell.execute_reply":"2023-05-19T15:08:18.106501Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"==================== Fold 1 ====================\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b1-f1951068.pth\" to /root/.cache/torch/checkpoints/efficientnet-b1-f1951068.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=31519111.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d430d13c245649b4913d383ed3a721d9"}},"metadata":{}},{"name":"stdout","text":"\nLoaded pretrained weights for efficientnet-b1\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/10 [00:00<?, ?it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=334.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0f69b7701bd4ca2867d285aede4d6ca"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 1/10 [07:42<1:09:26, 462.97s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 001: | Loss: 0.752 | Train acc: 0.528 | Val acc: 0.654 | Val roc_auc: 0.922 | Training time: 0:07:42\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=334.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6df4ed5458f84e7fb5b3dad56c11e6ac"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 2/10 [13:36<57:20, 430.01s/it]  ","output_type":"stream"},{"name":"stdout","text":"Epoch 002: | Loss: 0.270 | Train acc: 0.686 | Val acc: 0.734 | Val roc_auc: 0.930 | Training time: 0:05:52\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=334.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0444ee3360794306a589b2cf09a52d2a"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 3/10 [19:29<47:29, 407.03s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 003: | Loss: 0.168 | Train acc: 0.735 | Val acc: 0.751 | Val roc_auc: 0.932 | Training time: 0:05:53\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=334.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"296a00e1177e40b1a887530ca9897c37"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 4/10 [25:19<39:00, 390.05s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 004: | Loss: 0.106 | Train acc: 0.768 | Val acc: 0.786 | Val roc_auc: 0.932 | Training time: 0:05:50\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=334.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5085650dede74d78b666c4ee7aad33d1"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 5/10 [31:12<31:34, 378.83s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 005: | Loss: 0.089 | Train acc: 0.802 | Val acc: 0.780 | Val roc_auc: 0.939 | Training time: 0:05:52\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=334.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbe5a29e0414465ea99f0b62df40f92b"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 6/10 [37:04<24:42, 370.61s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 006: | Loss: 0.069 | Train acc: 0.818 | Val acc: 0.798 | Val roc_auc: 0.940 | Training time: 0:05:51\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=334.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb72f3b7b44642969ae2992ba579b9ba"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 7/10 [42:53<18:12, 364.28s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 007: | Loss: 0.039 | Train acc: 0.835 | Val acc: 0.760 | Val roc_auc: 0.937 | Training time: 0:05:49\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=334.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b79458e2d20c4301aa01bc879c984b24"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 8/10 [48:43<11:59, 359.94s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 008: | Loss: 0.050 | Train acc: 0.834 | Val acc: 0.744 | Val roc_auc: 0.937 | Training time: 0:05:49\nEpoch     8: reducing learning rate of group 0 to 4.0000e-05.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=334.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ef3e026246948119c02a9875dda5145"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [54:36<05:57, 357.93s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 009: | Loss: 0.028 | Train acc: 0.858 | Val acc: 0.803 | Val roc_auc: 0.945 | Training time: 0:05:53\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=334.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6602604d8dfa44e088a62fe7030285d7"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [1:00:28<00:00, 362.87s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 010: | Loss: 0.024 | Train acc: 0.870 | Val acc: 0.802 | Val roc_auc: 0.943 | Training time: 0:05:52\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"acc  0.8991512730903645\nprec  0.6971524049530845\nrec  0.8117222692924377\nf1  0.7397243936628836\nroc  0.8959216767319905\nFalse Negative Rate for mel: 22.89%\n==================== Fold 2 ====================\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/10 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Loaded pretrained weights for efficientnet-b1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=334.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a6bfd070cd3415f8f6969bb4c3a3660"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 1/10 [05:53<52:59, 353.28s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 001: | Loss: 0.733 | Train acc: 0.523 | Val acc: 0.599 | Val roc_auc: 0.915 | Training time: 0:05:53\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=334.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8affc5598cfa44edbc03832fbacb9806"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 2/10 [11:45<47:03, 352.98s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 002: | Loss: 0.253 | Train acc: 0.677 | Val acc: 0.654 | Val roc_auc: 0.939 | Training time: 0:05:52\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=334.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c2ca49b42ec47b8a4b27bf3bb65f763"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 3/10 [17:35<41:05, 352.16s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 003: | Loss: 0.148 | Train acc: 0.737 | Val acc: 0.682 | Val roc_auc: 0.931 | Training time: 0:05:50\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=334.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1798fa41654b4413ab16f1d7a7b3d883"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 4/10 [23:26<35:10, 351.79s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 004: | Loss: 0.106 | Train acc: 0.756 | Val acc: 0.712 | Val roc_auc: 0.930 | Training time: 0:05:50\nEpoch     4: reducing learning rate of group 0 to 4.0000e-05.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=334.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21af8fe87af34cea8b2ba21b1306948b"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 5/10 [29:17<29:17, 351.41s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 005: | Loss: 0.062 | Train acc: 0.796 | Val acc: 0.761 | Val roc_auc: 0.940 | Training time: 0:05:50\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=334.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7926bd9b8524ac2962b24c058f7d93c"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 6/10 [35:09<23:26, 351.54s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 006: | Loss: 0.047 | Train acc: 0.821 | Val acc: 0.763 | Val roc_auc: 0.936 | Training time: 0:05:51\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=334.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d4534a38e03489fbcf2cbda17f63859"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 7/10 [41:06<17:40, 353.36s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 007: | Loss: 0.039 | Train acc: 0.834 | Val acc: 0.766 | Val roc_auc: 0.941 | Training time: 0:05:57\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=334.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be7277390aa34b1e99cd343891e8e9b3"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 8/10 [47:03<11:48, 354.48s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 008: | Loss: 0.037 | Train acc: 0.835 | Val acc: 0.768 | Val roc_auc: 0.941 | Training time: 0:05:57\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=334.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e084ec9ae6d44785a9d3fdbab5d71292"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [52:56<05:53, 353.93s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 009: | Loss: 0.028 | Train acc: 0.856 | Val acc: 0.729 | Val roc_auc: 0.941 | Training time: 0:05:52\nEpoch     9: reducing learning rate of group 0 to 1.6000e-05.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=334.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf6dddecac564a4fb7c59e7ce8685a76"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [58:51<00:00, 353.14s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 010: | Loss: 0.026 | Train acc: 0.853 | Val acc: 0.764 | Val roc_auc: 0.943 | Training time: 0:05:54\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"acc  0.8966550174737893\nprec  0.6772036148222492\nrec  0.8410804014200589\nf1  0.7404851447633097\nroc  0.911408495270028\nFalse Negative Rate for mel: 21.69%\n==================== Fold 3 ====================\nLoaded pretrained weights for efficientnet-b1\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/10 [00:00<?, ?it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=334.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b18a57bd5b4f4875a716d5f37e852779"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 1/10 [05:52<52:56, 352.96s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 001: | Loss: 0.727 | Train acc: 0.521 | Val acc: 0.700 | Val roc_auc: 0.902 | Training time: 0:05:52\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=334.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea31e09d43894eae893fdb0c7d6ea06e"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 2/10 [11:45<47:03, 352.89s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 002: | Loss: 0.254 | Train acc: 0.680 | Val acc: 0.699 | Val roc_auc: 0.932 | Training time: 0:05:52\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=334.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7dff30ae29564353a34c0c0b6552563a"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 3/10 [17:39<41:11, 353.02s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 003: | Loss: 0.153 | Train acc: 0.744 | Val acc: 0.726 | Val roc_auc: 0.921 | Training time: 0:05:53\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=334.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d87bd7112ecf4a8b93cf78756a44712f"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 4/10 [23:34<35:22, 353.68s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 004: | Loss: 0.096 | Train acc: 0.773 | Val acc: 0.703 | Val roc_auc: 0.934 | Training time: 0:05:55\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=334.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13684e00694642f68b22b6699f2a143f"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 5/10 [29:29<29:30, 354.09s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 005: | Loss: 0.083 | Train acc: 0.789 | Val acc: 0.682 | Val roc_auc: 0.931 | Training time: 0:05:55\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=334.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9051a4f8a9b34fa3b92c4ee2a254ea57"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 6/10 [35:18<23:30, 352.71s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 006: | Loss: 0.067 | Train acc: 0.803 | Val acc: 0.781 | Val roc_auc: 0.929 | Training time: 0:05:49\nEpoch     6: reducing learning rate of group 0 to 4.0000e-05.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=334.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52e4f17b63bb437091268fe2adbcfb77"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 7/10 [41:09<17:36, 352.01s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 007: | Loss: 0.040 | Train acc: 0.843 | Val acc: 0.803 | Val roc_auc: 0.938 | Training time: 0:05:50\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=334.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9f75f765bb04ac9bea2cbb4d4f02619"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 8/10 [46:59<11:42, 351.48s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 008: | Loss: 0.030 | Train acc: 0.849 | Val acc: 0.811 | Val roc_auc: 0.931 | Training time: 0:05:50\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=334.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fd969482ef94de5a2c56dc08b1c4a6e"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [52:49<05:51, 351.10s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 009: | Loss: 0.023 | Train acc: 0.861 | Val acc: 0.793 | Val roc_auc: 0.936 | Training time: 0:05:50\nEpoch     9: reducing learning rate of group 0 to 1.6000e-05.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=334.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d181b3aae40447ebb2f091bf588d035f"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 9/10 [58:39<06:31, 391.09s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 010: | Loss: 0.021 | Train acc: 0.878 | Val acc: 0.810 | Val roc_auc: 0.938 | Training time: 0:05:50\nEarly stopping. Best Val roc_auc: 0.938\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"acc  0.9026460309535697\nprec  0.6608934576090318\nrec  0.7905219352914641\nf1  0.7147997197281858\nroc  0.8848558329180335\nFalse Negative Rate for mel: 38.55%\n","output_type":"stream"}]},{"cell_type":"code","source":"test_loader = DataLoader(dataset=test, batch_size=8, shuffle=False,num_workers=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.dx.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = torch.load('/kaggle/working/model.pth')\nmodel.eval()  # switch model to the evaluation mode\npreds = torch.zeros((len(test), 7), dtype=torch.float32, device=device)\nwith torch.no_grad():\n\n    for i, x_test in enumerate(test_loader):\n        x_test[0] = torch.tensor(x_test[0], device=device, dtype=torch.float32)\n        x_test[1] = torch.tensor(x_test[1], device=device, dtype=torch.float32)\n#         z_test = model(x_test)\n        z_test = model(x_test[0],x_test[1])\n        z_test = torch.softmax(z_test, dim=1) # use softmax to convert logits to probabilities\n        preds[i*x_test[0].shape[0]:i*x_test[0].shape[0] + x_test[0].shape[0]] += z_test\n\n\n\ngc.collect()   \n           \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\n\nfrom sklearn.metrics import accuracy_score, precision_score,recall_score, f1_score\n\nfrom sklearn.preprocessing import LabelBinarizer\n\n# Convert the target data to one-hot encoded format\nlb = LabelBinarizer()\ntest_labels = lb.fit_transform(test_df['target'])\n\n# Get predictions for the test set\ntest_preds = preds.cpu()\n\n# Convert the predictions to one-hot encoded format if needed\nif len(test_preds.shape) > 1 and test_preds.shape[1] > 1:\n    test_preds = np.argmax(test_preds, axis=1)\n    test_preds = lb.transform(test_preds)\n\n# Calculate metrics\nacc = accuracy_score(test_labels, test_preds)\nprec = precision_score(test_labels, test_preds, average='macro')\nrec = recall_score(test_labels, test_preds, average='macro')\nf1 = f1_score(test_labels, test_preds, average='macro')\nroc = roc_auc_score(test_labels, test_preds, multi_class='ovr')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"acc \", acc)\nprint(\"prec \",prec)\nprint(\"rec \",rec)\nprint(\"f1 \",f1)\nprint(\"roc \",roc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Generate the confusion matrix\nconf_matrix = confusion_matrix(test_labels.argmax(axis=1), test_preds.argmax(axis=1))\n\n# Create a heatmap of the confusion matrix\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n\n# Set the axis labels and title\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title('Confusion Matrix')\n\n# Display the plot\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract the row and column corresponding to class 4: mel\nclass_idx = 4\nfn = conf_matrix[class_idx, :].sum() - conf_matrix[class_idx, class_idx]\n\n# Calculate the percentage of instances from class 4 that were classified as another class\nfn_percent = (fn / conf_matrix[class_idx, :].sum()) * 100\n\n# Print the results\nprint(f\"False Negative Rate for mel: {fn_percent:.2f}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}